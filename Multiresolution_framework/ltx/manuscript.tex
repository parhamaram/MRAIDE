\documentclass[review,authoryear,3p]{elsarticle}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{setspace} 
 \usepackage[usenames,dvipsnames]{color}  
%This bit is how to use hyperlink without  coloured rectangles around it
\usepackage{float}
% \usepackage{hyperref}
 % \hypersetup{colorlinks,linkcolor=black,filecolor=black,urlcolor=black,citecolor=black}
 \newcommand{\dean}[1]{\textcolor{green}{#1}}
 \newcommand{\parham}[1]{\textcolor{blue}{#1}}
 \newcommand{\ken}[1]{\textcolor{red}{#1}}    
  

\journal{Neuroimage}
\begin{document}
\begin{frontmatter}
\title{Spatiotemporal Multi-Resolution Approximation of the Amari Type Neural Field Model}
  
\author[TNG]{P. Aram\corref{cor1}}
\ead{parham.aram@univ-amu.fr}
\author[DEEE,BI]{D. R. Freestone}
\ead{deanrf@unimelb.edu.au} 
\author[CU]{M. Dewar}
\ead{md@bit.ly}
\author[UM]{K. Scerri}
\ead{kenneth.scerri@um.edu.mt} 
 \author[TNG]{V. Jirsa}
\ead{viktor.jirsa@univ-amu.fr}
\author[DEEE,BI]{D. B. Grayden}
\ead{grayden@unimelb.edu.au}
\author[US]{V. Kadirkamanathan}
\ead{visakan@sheffield.ac.uk}

\address[TNG]{Theoretical Neuroscience Group, UMR 1106, Institut de Neurosciences des Systemes, 13385 Marseille, France}
\address[DEEE]{NeuroEngineering Laboratory, Department of Electrical and Electronic Engineering, University of Melbourne, Melbourne, VIC, Australia}
\address[CU]{bit.ly, New York City, USA}
\address[UM]{Department of Systems and Control Engineering, University of Malta, Msida, MSD, Malta}
 \address[US]{Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield, UK}
 \address[BI]{The Bionics Institute, East Melbourne, VIC, Australia}

\cortext[cor1]{Corresponding author}

\begin{abstract}
%\boldmath
Neural fields are spatially continuous state variables described by integro-differential equations, which are well suited to describe the spatiotemporal evolution of cortical activations on multiple scales. Here we develop a multi-resolution approximation (MRA) framework for the integro-difference equation (IDE) neural field model based on semi-orthogonal cardinal B-spline wavelets. In this way, a flexible framework is created, whereby both macroscopic and microscopic behavior of the system can be represented simultaneously. State and parameter estimation is performed using the expectation maximization (EM) algorithm. A synthetic example is provided
to demonstrate the framework.
\end{abstract} 
\begin{keyword}
  Neural field model, multi-resolution approximation (MRA), expectation maximization (EM) algorithm
\end{keyword}
\end{frontmatter}
\section{Introduction}
The human cerebral cortex has a multi-resolution architecture, where spatial scales for information processing range from ion channels, to single neurons, to networks of millions of neurons. This multi-resolution cortical architecture poses major modeling challenges to efficiently describe the brain's dynamics. This paper introduces a multi-resolution data-driven framework for neural field modeling, the multi-resolution approximate integro-difference equation (MRAIDE) to address this challenge. 

Neural field models describe the mass action of the central nervous system and are a critical link in our understanding of the biophysics leading to the generation of  electroencephalography (EEG) and magnetoencephalography (MEG) signals. The key components of these models typically describe the macroscopic dynamics of the human brain, but can also be descriptive of finer-scale neurodynamics. Examples are the post-synaptic response kernels (pulse to wave conversion) and the activation function (wave to pulse conversion) \citep{Jirsa1996,Jirsa1997}. The former can be descriptive of inhibitory and excitatory post-synaptic potentials in populations of microscopic single neural models, such as integrate and fire neurons, or an ensemble response to stimulation in macroscopic neural mass models \citep{Stefanescu2008}. The latter can be used to model spiking statistics across spatial scales from single neurons (where it can be considered a cumulative distribution function (CDF) of the probability of firing) as mean firing rates of neural masses. The key factor linking the functions of neural mass models to particular spatial scales is the connectivity, hence the ability to infer a multi-resolution connectivity kernel will enable the formulation of a multi-resolution neural field model.  

The utility of these models for answering questions in clinical neuroscience and neurology lies in the ability to infer physiological parameters from electrophysiological data. The ability to create patient-specific neural models will contribute to our knowledge base of diseases such as epilepsy and will enable the development of new treatment strategies. Large-scale neuroinformatic efforts, such as the Virtual Brain Project (www.thevirtualbrain.org \citep{Jirsa2010}), are on the way to enable patient-specific full brain modeling. This is particularly relevant to the advent of new devices that use therapeutic electrical stimulation. Stimulation strategies for devices currently operate in an open loop, where stimulation parameters are chosen using a process of trial and error. Therefore, there exists enormous potential to improve the performance of these devices using systems theory, which in turn requires a suitable dynamic model. Neural mass and neural field models are ideal candidates for estimation algorithms due to their strong links with physiology and their parsimony. The main difference between these two classes is that neural field models represent a cortical sheet, making a continuum approximation to describe the spatiotemporal evolution of neural dynamics (such as mean firing rates or mean membrane potentials), while neural mass models describe ensembles of neurons at a localized point, which may be networked to multiple points. Both neural field and neural mass models make a mean-field approximation to describe the mass action of the brain. It is expected that parameters of these models will be patient-specific and will, therefore, need to be inferred from data. 

The multi-resolution architecture of the brain and connectivity in particular will play an important role in this context for multiple reasons. First, there is an on-going debate about the organizational level of the brain at which cognition and behavior is best represented. While clearly single neurons show response changes that map back to learning, memory and motor behavior, much of the recent work in neuroscience suggest that these elementary features must be organized at a higher level to provide the richness and diversity of the behaving system.  For example, functional neuroimaging work has confirmed that specific parts of visual cortex are more responsive to particular types of stimuli (e.g. faces), but the specificity of this response is dependent on the large-scale pattern of activity across most visual cortical areas \citep{Haxby2001}. Further, the evolution of diffusion magnetic resonance imaging (dMRI) has led to the development of tensor-based tractography, which allows for \emph{in vivo} images of the white matter skeleton of any brain. Improvements of the MR sequences (e.g. diffusion spectrum imaging) and tractography analysis have made it possible to use tractography as a standard to define connectivity \citep{Hagmann2008}. Hence individualized connectivity matrices can be developed for brain models enabling patient-specific functional studies and need to be estimated from the experimental data.                          

The first work (to the authors best knowledge) describing data-driven mesoscopic neural modeling used a neural mass model to fit EEG data~\citep{Valdes1999}. This approach was extended to coupled neural masses through a Bayesian estimation scheme called dynamic causal modeling (DCM)~\citep{David2003}. Following this work, data-driven modeling was extended to continuum field equations that explained the richer dynamics of spatiotemporal neural fields \citep{Galka2008,schiff2008kalman,Daunizeau2009, Pinotsis2012}. Most recently, a framework was developed where a finite-element model of the neural field (via a dynamic Galerkin projection) was formed, using a basis function decomposition, to transform the PDE neural field equations into a finite-dimensional system to facilitate efficient state and parameter estimation~\citep{Freestone2011}. This paper is an extension to the aforementioned study, where we derive a neural field state-space model that accounts for the multi-resolution architecture and spatial dynamics of the human cortex. In this way, a flexible framework is created, whereby both macroscopic and microscopic behavior of the system can be represented simultaneously and completely.

\section{Multi-Resolution Cortical Architecture}
The human neocortex has an inherent multi-resolution architecture. The spatiotemporal neural field can be written as 
\begin{equation}
	v\left(\mathbf{r},t\right) = \sum_{j} v_j\left(\mathbf{r},t\right),
\end{equation}
where $v\left(\mathbf{r},t\right)$ is a voltage field that may be measured with a high-resolution multi-electrode array or voltage sensitive dye, $\mathbf{r}\in \mathbb{R}^n$ (where $n\le3$) describes the spatial location within the field, $t$ denotes time, and $j$ indexes the different levels of resolution in the field. This multi-resolution structure is depicted in Fig.~\ref{fig:MultiLayerFieldModel}.

The multi-resolution structure has been described by numerous methods. For example, this idea of multi-resolution can be thought of as the generalization of modeling the layers of the cortex separately, where the connectivity kernel, or neural foot-print, has varying widths \citep{Wilson1973}.

Typically, the experimentalist only has access to the net field generated by the multi-resolution architecture of the cortex. Following this, it is natural to ask how do we best describe the multi-resolution structure of the neural system. The solution to this problem was proposed by \citet{Breakspear2005} in using a wavelet decomposition. This paper is directed at developing a framework for patient-specific multi-resolution neural field models, forming a fundamental link between data and theory. 
\section{IDE Neural Field Model}
In a small network with no time delays the single layer homogeneous neural field model, in the most general form, is described by the equation
\begin{equation}
	\label{FullDoubleIntModel} \underbrace{v\left(\mathbf{r},t\right)}_{\text{field}} =
	\int_{-\infty}^t 
	\underbrace{h\left(t - t'\right)}_{\text{synapse}} \int_\Omega
	\underbrace{w\left(\mathbf{r},\mathbf{r}'\right)}_{\text{connectivity}} 
	\underbrace{f\left( v\left( \mathbf{r}',t'\right)\right)}_{\text{firing}}
	\, \mathrm{d}\mathbf{r}'\mathrm{d}t',
\end{equation}
where the post-synaptic membrane voltage at time $t$ of a population of neurons at position $\mathbf r$ within the spatial domain $\Omega$ is denoted by $v\left(\mathbf r,t\right)$. The function $h(t)$ describes the post-synaptic response kernel, $w\left(\mathbf{r},\mathbf{r}'\right)$ describes the connectivity kernel and $f(v(\mathbf{r},t))$ describes the relationship between the mean membrane potential and the mean firing rate. There are various forms of $h(t)$ that have been proposed in the literature, with different levels of complexity, leading to first or second-order differential equations. These are plotted in Fig.~\ref{fig:Modelcomponents}, showing the second-order (finite rise time) and first-order (instantaneous response) kernels. The second-order synaptic kernel reproduces experimental excitatory and inhibitory post-synaptic potentials (EPSPs and IPSPs) features \citep{VanRotterdam1982}. Similarly, both the connectivity kernel and the activity function (firing rate) can take various forms. These are also shown in Fig.~\ref{fig:Modelcomponents}. The form of $w(\mathbf{r},\mathbf{r}')$ typically describes a Laplacian (exponential) or Gaussian decay in connectivity strength from any point in the field \citep{Breakspear2010,Atay2005}. By assuming the form of $h(t)$ is the same across layers (scales) the Amari style neural field model is formed, incorporating a multi-layer structure into the connectivity kernel. The connectivity kernel then can be written as a sum of weighted (Gaussian, Laplacian or B-Spline) basis functions, where the weights can be thought of as the synaptic efficiency or coupling strength and positive and negative weights describe excitation and inhibition, respectively. In this way, the connectivity kernel typically takes the form of a Mexican hat (Gaussian shape within layer connectivity) or Wizard hat (Laplacian shape within layer) as depicted in Fig.~\ref{fig:Modelcomponents}.

The stochastic IDE form of the Amari neural field formulation~\cite{Amari1977} is given by (see~\citet{Freestone2011} for a full derivation)
\begin{equation}\label{eq:DiscreteTimeModel}
	v_{t+1}\left(\mathbf{r}\right) = 
	\xi v_t\left(\mathbf{r}\right) + 
	T_s \int_\Omega { 
	    w\left(\mathbf{r},\mathbf{r'}\right)
	    f\left(v_t\left(\mathbf{r}'\right)\right) 
	\, \mathrm{d}\mathbf{r}'} 
	+ e_t\left(\mathbf{r}\right), 
\end{equation}
where in this first-order (in time) formulation of the model the membrane dynamics are included through the parameter $\xi=1-T_s/\tau$, $\tau$ is the membrane time constant and $T_s$ is the sampling time step. The term $e_t(\mathbf r)$ is a zero mean Gaussian disturbance, spatially colored but temporally white, with covariance function 
\begin{equation}
cov\left(e_{t}\left(\mathbf{r}\right),e_{t+t'}\left(\mathbf{r'}\right)\right)=\sigma_d\eta(\mathbf{r}-\mathbf{r'})\delta(t-t'),
\label{eq:FieldDisturbance}
\end{equation}
where $\eta(\mathbf{r}-\mathbf{r'})$ is a spatially homogeneous covariance function, $\sigma_d$ is disturbance variance and $\delta(\cdot)$ is the Dirac-delta function. %$ = \varsigma v_t(\mathbf{r})$ \cite{VanRotterdam1982,Murphy2009}.

The observation equation describing the intracranial electrophysiological recordings is given by
\begin{equation}\label{eq:ObservationEquation}
	y_t(\mathbf{r}_{n_y}) = \int_{\Omega} { m\left(\mathbf{r}_{n_y}-\mathbf{r}'\right) v_t\left(\mathbf{r}'\right) \, \mathrm{d}\mathbf{r}'} + \epsilon_t(\mathbf{r}_{n_y}), 
\end{equation}
where $m\left(\mathbf{r}_{n_y}-\mathbf{r}'\right)$ is the observation kernel at location $\mathbf{r}_{n_y}$ and  $\boldsymbol{\epsilon}_{t}\sim \mathcal{N}\left(\mathbf{0},\mathbf{\Sigma}_{\epsilon}\right)$ is an independent and identically distributed (i.i.d.) Gaussian white noise process with the covariance matrix $\mathbf{\Sigma}_{\epsilon}=\sigma^2_{\epsilon}\mathbf I_{n_y}$, where $\mathbf I$ denotes the identity matrix. The observation kernel models the pickup range of the electrical fields of the brain. The lead field parameters, which incorporate information about a realistic head model~\citep{Jirsa2007}, are not included in the observation equation as the intracranial recordings are only considered here. 
\section{MRA of the IDE in State-Space}
The purpose of forming the multi-resolution approximation (MRA) of the integro-difference equation (IDE) is to form a multi-resolution finite-dimensional state-space model that best captures the spatiotemporal characteristics of the neural field. Given such a model, it is then possible to perform state and parameter estimation in an efficient and robust manner, thus allowing for subject-specific models. The goal of this section is to demonstrate how to formulate a state-space model in a canonical form such that standard algorithms may be applied to estimate the multi-resolution connectivity structure.   

The multi-resolution approximation \citep{Mallat1989a} of the neural IDE (MRAIDE) is obtained by decomposing both the field, $v_t(\cdot)$, and the connectivity kernel, $w(\cdot)$, (assuming square-integrable functions) using translations and dilations of a scaling function $\phi(\mathbf{r})$ and a mother wavelet $\psi(\mathbf{r})$. Considering a  one-dimensional field, the static connectivity kernel is decomposed as,
\begin{equation}
 w\left(r\right)=\sum_{l\in \mathbb{Z}}a_{j_0,l} \underbrace{\phi_{j_0,l}\left(r\right)}_{\text{scaling functions}} + \sum_{j\geq j_0}^{\infty} \sum_{l \in \mathbb{Z}}c_{j,l} \underbrace{\psi_{j,l}\left(r\right)}_{\text{wavelets}}, 
\label{eq:KernelExpansion}
\end{equation}
where $a_{j_0,l}$ are the approximation coefficients at the lowest scale $j_0$, and $c_{j,l}$ are the detail coefficients at different scales $j$, with
\begin{align}
\phi_{j,l}\left(r\right) =& 2^{\frac{j}{2}}\phi\left(2^j r-l\right) \label{eq:generalscalingfinction}\\	
\psi_{j,l}\left(r\right) =& 2^{\frac{j}{2}}\psi\left(2^j r-l\right).  \label{eq:generalwaveletfinction}
\end{align}
The parameters $j$ and $l$ control the scale (dilation) and translation (spatial shift), respectively. The number of spatial shifts, $l$, is dependent on the scale, $j$, and can be chosen such that the basis functions cover the spatial domain of interest. For example, at scales corresponding to higher spatial frequencies a greater number of wavelets, and thus spatial shifts are required to adequately sample the spatial characteristics of the field. The number of scales depends on the spectral characteristics of the field, where higher spatial frequencies require  more scales. Spatial frequency analysis will be described later in Section~\ref{sec:freq_anal} in greater detail. Scaling functions retain the lowest frequency components, due to their low-pass properties, while the wavelet functions extract successively higher frequency components due to their band-pass characteristics. 

The dynamic neural field is decomposed using
\begin{equation}
 v_t\left(r\right)=\sum_{l \in \mathbb{Z}}x_{t,j_{0},l} \underbrace{\phi_{j_0,l}\left(r\right)}_{\text{scaling functions}} + \sum_{j\geq j_0}^{\infty} \sum_{l \in \mathbb{Z}} \check{x}_{t,j,l} \underbrace{\psi_{j,l}\left(r\right)}_{\text{wavelets}},
\label{eq:FieldExpansion}
\end{equation}
where $x_{t,j_{0},l}$ and $\check{x}_{t,j,l} $ are the dynamic coefficients of the expansion, constituting the state vector at time $t$. The state vector has the same units as the neural field (volts). However, the states are weights for particular levels of resolution, where $v_t\left(r\right)$ is the total net field. The decomposition enables a separation of the spatial characteristics, which are considered static functions that are weighted by dynamic coefficients.

Eqs.~\eqref{eq:KernelExpansion} and \eqref{eq:FieldExpansion} are infinite series expansions but must be truncated to some level $j,$ in order to solve the estimation problem. In other words, the neural field must be band-limited up to a given spatial frequency. 

Now we will simplify the notation by defining vectors that contain all the translations of the wavelets and scaling functions 
\begin{align}      
	\boldsymbol\phi_{j_0}(r) \triangleq&\left\lbrace{\phi_{j_0,l}(r)}:l \in \mathbb{Z} \right\rbrace \\
	\boldsymbol\psi_{j}(r) \triangleq& \left\lbrace{\psi_{j,l}(r)}:l \in \mathbb{Z} \right\rbrace\\
	\mathbf{a}_{j_0} \triangleq& \left\lbrace a_{j_0, l}:l \in \mathbb{Z} \right\rbrace \\
	\mathbf{c}_{j} \triangleq& \left\lbrace c_{j, l}:l \in \mathbb{Z} \right\rbrace \\
	\mathbf{x}_{t,j_0} \triangleq& \left\lbrace{x}_{t,j_{0},l}:l \in \mathbb{Z} \right\rbrace \\
	\check{\mathbf{x}}_{t,j} \triangleq& \left\lbrace{\check{x}}_{t,j,l}:l \in \mathbb{Z} \right\rbrace.
\end{align}
Following this we can define the vectors 
\begin{align}
\boldsymbol\theta^\top \triangleq& [\begin{array}{ccccc} \mathbf{a}_{j_0}^\top & \mathbf{c}_{j_0}^\top & \mathbf{c}_{j_0+1}^\top & \cdots & \mathbf{c}_{j}^\top \end{array}] 
\label{KernelWeights} \\
\mathbf{x}_{t}^\top \triangleq& [\begin{array}{ccccc}\mathbf{x}_{t,j_{0}}^\top &  \check{\mathbf{x}}_{t,j_{0}}^\top & \check{\mathbf{x}}_{t,j_{0}+1}^\top & \cdots & \check{\mathbf{x}}_{t,j}^\top\end{array}]
\label{FieldWeights} \\
\label{KernelBasisVector}
\boldsymbol\lambda^\top(r) \triangleq& \left[
\begin{array}{ccccc} \boldsymbol\phi_{j_0}^\top(r) &
\boldsymbol\psi_{j_0}^\top(r) & 
\boldsymbol\psi_{j_0+1}^\top(r) &
\cdots &
\boldsymbol\psi_{j}^\top(r)\end{array}\right] \\
\label{FieldBasisVector}
\boldsymbol\mu^\top (r) \triangleq& \left[
\begin{array}{ccccc}\boldsymbol\phi_{j_0}^\top(r) &
\boldsymbol\psi_{j_0}^\top(r) & 
\boldsymbol\psi_{j_0+1}^\top(r) &
\cdots &
\boldsymbol\psi_{j}^\top(r)\end{array}\right],
\end{align}
which allow us to write the connectivity kernel and neural field  decomposition in the compact form of
\begin{align}
	w\left(r\right) &\approx \boldsymbol\theta^\top\boldsymbol\lambda\left(r\right) 
	\label{eq:KernelFiniteExpansion} \\
	v_t\left(r\right) &\approx \boldsymbol\mu^\top\left(r\right)\mathbf{x}_t.
	\label{eq:FieldFiniteExpansion}
\end{align}
Now we have the compact form of the decomposition we can substitute this into the neural field Eq.~\eqref{eq:DiscreteTimeModel} giving
\begin{equation}\label{eq:ApproxDiscreteTimeModel}
	\boldsymbol\mu^\top\left(r\right)\mathbf{x}_{t+1} = 
	\xi \boldsymbol\mu^\top\left(r\right)\mathbf{x}_t + 
	T_s \int_\Omega { 
	    \boldsymbol\theta^\top\boldsymbol\lambda\left(r-r'\right)
	    f\left(\boldsymbol\mu^\top\left(r'\right)\mathbf{x}_t\right) 
	\, \mathrm{d}r'}  
	+ e_t\left(r\right).
\end{equation}
The aim of the next part of the derivation is to isolate the state vector on the left hand side of the equation. The conceptual framework and the key results can be interpreted without following this derivation in detail. To isolate the state vector we first multiply both sides of Eq.~\eqref{eq:ApproxDiscreteTimeModel} by $\boldsymbol\mu\left(r\right)$ and integrate over space giving 
\begin{align}\label{eq:ApproxDiscreteTimeModel2}
	\int_{\Omega} \boldsymbol\mu\left(r\right)\boldsymbol\mu^\top\left(r\right) \mathrm{d}r \mathbf{x}_{t+1} &= 
	\xi \int_{\Omega}\boldsymbol\mu\left(r\right)\boldsymbol\mu^\top\left(r\right) \mathrm{d}r \mathbf{x}_t + 
	T_s \int_{\Omega}\boldsymbol\mu\left(r\right)\int_\Omega { 
	    \boldsymbol\theta^\top\boldsymbol\lambda\left(r-r'\right)
	    f\left(\boldsymbol\mu^\top\left(r'\right)\mathbf{x}_t\right) 
	\, \mathrm{d}r'\mathrm{d}r}  \nonumber\\
	&+ \int_{\Omega}\boldsymbol\mu\left(r\right)e_t\left(r\right)\mathrm{d}r.
\end{align}
To isolate the state vector, we now define the matrix 
\begin{equation}
	\label{eq:Lambdax}
	 \mathbf{\Lambda}_{x} \triangleq \int_{\Omega}\boldsymbol{\mu}\left(r\right)\boldsymbol{\mu}^\top\left(r\right) \mathrm{d}r,
\end{equation}
and substitute into Eq.~\eqref{eq:ApproxDiscreteTimeModel2} giving
\begin{equation}\label{eq:ApproxDiscreteTimeModel3}
	\mathbf{\Lambda}_{x} \mathbf{x}_{t+1} = 
	\xi \mathbf{\Lambda}_{x} \mathbf{x}_t + 
	T_s \int_{\Omega}\boldsymbol\mu\left(r\right)\int_\Omega { 
	    \boldsymbol\theta^\top\boldsymbol\lambda\left(r-r'\right)
	    f\left(\boldsymbol\mu^\top\left(r'\right)\mathbf{x}_t\right) 
	\, \mathrm{d}r'\mathrm{d}r}  
	+ \int_{\Omega}\boldsymbol{\mu}\left(r\right) e_t\left(r\right) \mathrm{d}r.
\end{equation}
Cross-multiplying by $\mathbf{\Lambda}_{x}^{-1}$ gives the state transition equation
\begin{equation}\label{eq:ApproxDiscreteTimeModel4}
	\mathbf{x}_{t+1} = 
	\xi \mathbf{x}_t + 
	T_s \mathbf{\Lambda}_{x}^{-1} \int_{\Omega}\boldsymbol\mu\left(r\right)\int_\Omega { 
	    \boldsymbol\theta^\top\boldsymbol\lambda\left(r-r'\right)
	    f\left(\boldsymbol\mu^\top\left(r'\right)\mathbf{x}_t\right) 
	\, \mathrm{d}r'\mathrm{d}r}  
	+ \mathbf{\Lambda}_{x}^{-1}\int_{\Omega}\boldsymbol{\mu}\left(r\right) e_t\left(r\right) \mathrm{d}r.
\end{equation}
A very nice property of the MRAIDE framework is the disturbance term becomes a vector valued, zero-mean normally distributed, white noise process 
\begin{equation}\label{eq:Disturbance}
\mathbf w_t= \mathbf{\Lambda}_{x}^{-1}\int_{\Omega}\boldsymbol\mu \left(r\right)e_t\left(r\right)\,\mathrm{d}r,
\end{equation}
with covariance (see \citet{Freestone2011} for proof)
\begin{equation}\label{eq:CovMatrix}
\boldsymbol\Sigma_w =\mathbf{\Lambda}_{x}^{-1}\iint\limits_{\boldsymbol\Omega}\boldsymbol\mu\left(r\right) \eta\left(r-r'\right)\boldsymbol\mu^{\top}\left(r'\right)\,\mathrm{d}r'\mathrm{d}r\mathbf{\Lambda}_{x}^{-\top}.
\end{equation} 

The state-transition equation can be simplified if the chosen family of scaling and wavelet functions are isotropic where
\begin{equation}
	\boldsymbol{\lambda}_{i}(r-r') = \boldsymbol{\lambda}(2\mathbf{c}_{i}+r'-r), 
\end{equation}
where $c_i$ is the centre of the $i^{th}$ basis function of the kernel decomposition. Following this, we can switch the order of operations with the inner product and convolution in Eq.~\eqref{eq:ApproxDiscreteTimeModel4}. With this switch the convolution is now between the scaling functions and wavelets for the field and the scaling functions and wavelets for the connectivity kernel. This convolution can be calculated analytically when using B-spline scaling and wavelet functions and can be predefined, since these are static functions. This has major computational advantages when solving the estimation problem. %\parham{Although this switch holds theoretically it should be noted that it will introduce numerical error, specially close to the edges, due to the finite extent of the field. } 
The predefined convolution can be written as
\begin{equation}\label{eq:Gammaij}
	\left[\Gamma(r')\right]_{:i} = T_s \mathbf{\Lambda}_{x}^{-1}\int_{\Omega} \boldsymbol\mu\left(r\right)\boldsymbol\lambda\left(2c_{i} + r'-r\right) \,\mathrm{d}r,
\end{equation} 
 where $\left[\Gamma(r')\right]_{:i}$ denotes the $i^{th}$ column of  $\left[\Gamma(r')\right]$ giving
\begin{equation}
	\mathbf{x}_{t+1} = 
	\xi \mathbf{x}_t + 
	\int_{\Omega} \Gamma\left(r'\right)f\left(\boldsymbol\mu^\top\left(r'\right) \mathbf{x}_t\right) 
	\, \mathrm{d}r' \boldsymbol\theta
	+ \mathbf w_t.
\end{equation}
The observation equation of the state-space model is found by substituting decomposition \eqref{eq:FieldFiniteExpansion}
 into Eq.~\eqref{eq:ObservationEquation} giving
\begin{equation}\label{eq:ReducedObservationEquation} 
	\mathbf{y}_t = \mathbf{C}\mathbf{x}_t + \boldsymbol{\epsilon}_t,
\end{equation}
where each element of the observation matrix, $\mathbf{C}$, is given by
\begin{equation}\label{eq:Observationmatrix}
	\mathbf{C}_{ik} \triangleq \int_{\Omega}m(r_i -r')\boldsymbol{\mu}_k(r') \, \mathrm{d}r'.
\end{equation}
\section{B-Spline MRAIDE in State-Space }
\subsection{A Brief Introduction to B-Spline Wavelets}
This section is included to provide the interested reader with an overview of the theory used in constructing the wavelets that form the basis of the multi-resolution model. Although a deep understanding of the theory presented in this section is not required for an understanding of the key results of the paper, it serves as a reference for implementing the methods.

B-spline functions are one of the most basic elements for wavelet construction. These functions are composed of piecewise polynomials combined smoothly at some breaking points (knots), which are equally spaced in the case of cardinal B-splines. The degree of smoothness is determined by the order of splines \citep{Goswami1999}, where the higher the order the smoother the resulting B-spline becomes (see Fig.~\ref{fig:Figure0}).

 
B-spline wavelet and scaling functions were formulated independently by \citet{Chui1992b}, \citet{Chui1992} and \citet{Unser1993}.  The scaling functions are $m^{th}$ order B-splines and the compact support wavelet functions are a linear combination of scaling functions. B-spline wavelet and scaling functions approach optimal time/frequency localization as the order of the spline increases. In fact, for the cubic B-spline scaling and wavelet functions it is already close to the optimal limit for Gaussian functions \citep{Unser1999}. 
%and they have a better approximation rate than other wavelets with the same number of vanishing moments 

B-spline wavelet and scaling functions are particularly suited in this framework due to the property of being able to analytically define the convolution and inner product to form MRAIDE components. The following summarizes some important characteristics of B-splines relevant to the proposed modeling framework. 

The $m^{th}$  order cardinal B-spline function is defined by the recurrence relation \citep{Chui1992} 
\begin{equation}
N_{m}\left(r\right) = \left(N_{m-1}\ast N_{1}\right)\left(r\right) = \int_0^{1} N_{m-1}\left( r-r'\right)\,\mathrm{d}r',
\label{SplineConvolutionIntegral}
\end{equation}
where $m>1$, $\ast$ denotes convolution, and $N_1\left(r\right)$ is the characteristic function of the unit interval $\left[ 0,1\right)$, also known as indicator function, i.e.
\begin{equation}
N_{1}\left(r\right)=
\begin{cases}
1 & \text{if $ 0\le r<1$}, \\
0 & \mathrm{elsewhere}.
\end{cases}
\end{equation}
Following this, a B-spline of any order, $N_m(r)$, can be computed using the recursive expression defined by \citet{DeBoor2001}
\begin{equation}\label{eq:MRA-DoBoorFormula}
 N_{m}\left(r\right)=\frac{r}{m-1}N_{m-1}\left(r\right)+\frac{m-r}{m-1}N_{m-1}\left(r-1\right) \quad m>1.
 \end{equation}
The most commonly used form of splines is the cubic spline $\left(m=4\right)$, comprised of third degree polynomials added together at the joining points, with an explicit expression given by
\begin{align}
3!N_{4}\left(r\right)=
\begin{cases}
r^3 & \text{if $ 0\le r\le1$}, \\
4-12r+12r^2-3r^3 & \text{if $1\le r\le2$}, \\
-44+60r-24r^2+3r^3 & \text{if $2\le r\le3$}, \\
64-48r+12r^2-r^3 & \text{if $3\le r\le4$}, \\
0 & \mathrm{elsewhere}.
\end{cases}
\end{align}
One important feature of the B-spline functions is the partition of unity property, meaning that the unity (zero spatial frequency) can be expressed as a linear sum of B-splines, i.e
\begin{equation}
	\sum_{l}N_m(r+l)\equiv1.
	\end{equation}
This is important as the underlying field can be reconstructed when it is saturated without introducing numerical errors which is not the case for example when Gaussian basis functions are used.
	
The convolution and inner product of B-spline functions are required in order to formulate the multi-resolution framework described in the previous section (construction of $\boldsymbol\Lambda_{x}$ and $\boldsymbol\Gamma$). To show how the convolution of two B-splines is calculated, Eq.~\eqref{SplineConvolutionIntegral} can be rewritten as $(m-1)$ convolutions of the indicator function with itself
\begin{equation}\label{eq:N1convolutions}
 N_{m}\left(r\right)=\underbrace{\left(N_{1}\ast N_{1}\ast \cdots \ast N_{1}\right)}_{m-1\quad \text{convolutions}}\left(r\right).
\end{equation}
Using the associativity property of convolution, we have
\setlength{\arraycolsep}{0.0em}
\begin{align}\label{eq:BsplineConvolution}
N_{m}\left( r\right) \ast N_{m'}\left(r\right)&=\underbrace{\overbrace{\left(N_{1} \ast \cdots \ast N_{1}\right)}^{m-1 \quad \text{convolutions}}\left(r\right) \ast \overbrace{\left(N_{1} \ast \cdots \ast N_{1}\right)}^{m'-1\quad \text{convolutions}}}_{m+m'-1 \quad \text{convolutions}}\left(r\right)\nonumber\\
&=N_{m+m'}\left(r\right).
\end{align}
A direct consequence of Eq.~\eqref{eq:BsplineConvolution} is the inner product between two B-splines is another translated B-spline such that
\begin{align}
 \left\langle N_{m}\left(r-l_{1}\right), N_{m'}\left(r-l_{2}\right)\right\rangle=&N_{m+m'}\left(m+l_{1}-l_{2}\right)\nonumber \\
=&N_{m+m'}\left(m'+l_{2}-l_{1}\right),
\label{eq:BsplineInnerProduct}
\end{align}
where $\left\langle \cdot,\cdot\right\rangle $ denotes the inner product. This holds as the support of $N_m\left(r\right)$ is $\left[ 0,m\right]$ and  is symmetric with respect to $r=\frac{m}{2}$, i.e. $ N_{m}\left(\frac{m}{2}+r\right)=N_{m}\left(\frac{m}{2}-r\right)$ (see \ref{ap:InnerProductOfBsplines} for explicit derivation). The values of $N_{m+m'}$ in Eq.~\eqref{eq:BsplineInnerProduct} can be easily determined recursively by evaluating Eq.~\eqref{eq:MRA-DoBoorFormula} at integer points, i.e.
 \begin{equation}\label{eq:MRA-recursiveBsplineatintegerpoints}
 \begin{cases}
 N_2(k)=\delta(k-1)\quad k\in \mathbb{Z}, \\
 N_{m}\left(k\right)=\frac{k}{m-1}N_{m-1}\left(k\right)+\frac{m-k}{m-1}N_{m-1}\left(k-1\right) \quad k=1,2,\dots,m-1.
  \end{cases}
 \end{equation}
Note $N_{m}\left(k\right)=0$ for $k\le0$ or $k\ge m$. 

The multi-resolution approximation using B-spline functions is completed by defining a two-scale relation pair, which relates the scaling functions and the wavelets at a given scale with the scaling function at the next higher scale. For B-spline scaling and wavelet functions of order $m$ the two-scale relation pair takes the form of \citep{Chui1992}
\begin{align}
 N_{m}\left(r\right)&=\sum_{n=0}^{m}  p_n N_{m}\left(2r-n\right) \label{eq:MRA-TwoScalepair1} \\
  \varphi_{m}\left(r\right) &= \sum_{n=0}^{3m-2} q_n N_{m}\left(2r-n\right)\label{eq:MRA-TwoScalepair2},
 \end{align}
where 
 \begin{align}
 p_n&=2^{-m+1} \binom{m}{n} \quad \text{ $0\le n\le m$} \label{eq:MRA-TwoScalepair1coefs}\\
q_n&= \left(-1\right)^n{2^{-m+1}}\sum_{l=0}^{m} \binom{m}{l} N_{2m}\left(n-l+1\right), \,  \text{ $0\le n\le 3m-2$}\label{eq:MRA-TwoScalepair2coefs}
 \end{align}
% and $\left[\cdot\right]_n$ denotes the $n^{th}$ element of the vector coefficients .

Fig.~\ref{fig:MRA-Figure1} shows the cubic B-spline scaling function and its associated wavelet function with dilation and translation parameters set to zero. Note in general the supports of B-spline scaling and wavelet functions are given by 
\begin{align}
	\mathrm{supp}(N_{m;j,l})&=\left[\frac{l}{2^j},\frac{m+l}{2^j}\right] \label{eq:ScalingSupport}\\  
  \mathrm{supp}(\varphi_{m;j,l})&=\left[\frac{l}{2^j},\frac{2m-1+l}{2^j}\right],\label{eq:WaveletSupport}
	\end{align}    
where subscripts $j$ and $l$ in Eqs.~\eqref{eq:ScalingSupport} and \eqref{eq:WaveletSupport} are introduced to $N_{m}(r)$ and $\varphi_{m}(r)$ to indicate the scale and translation parameters as defined in Eqs~\eqref{eq:generalscalingfinction} and \eqref{eq:generalwaveletfinction}.

 
By exploiting Eqs.~\eqref{eq:BsplineConvolution} and \eqref{eq:BsplineInnerProduct}, the integrals in Eqs.~\eqref{eq:Lambdax} and \eqref{eq:Gammaij} can be computed analytically. In constructing $\boldsymbol\Lambda_{x}$, it is important to note that B-spline scaling and wavelet functions possess the following orthogonality properties \citep{Unser1993}: 
\begin{equation}
  \left\langle \varphi_{m;j_1,l_1}(r),\varphi_{m;j_2,l_2}(r)\right\rangle =0  \quad \mathrm{for} \quad j_1\neq j_2
 \label{eq:MRA-PsiPsiOrthogonality} 
 \end{equation}
 \begin{equation}
  \left\langle N_{m;j_1,l_1}(r),\varphi_{m;j_2,l_2}(r)\right\rangle =0  \quad \mathrm{for} \quad j_1\leq j_2.
 \label{eq:MRA-PhiPsiOrthogonality}
 \end{equation}
Note from Eq.~\eqref{eq:MRA-PsiPsiOrthogonality} B-spline wavelets are semi-orthogonal as they are not orthogonal with respect to translation on a given scale.

In order to analytically calculate elements of $\boldsymbol\Lambda_{x}$ and $\boldsymbol\Gamma$, the scaling and wavelet basis functions must be expanded in terms of $N_m$ at the appropriate scale using the two-scale relation pair defined in Eqs.~(\eqref{eq:MRA-TwoScalepair1}-\eqref{eq:MRA-TwoScalepair2coefs}). 
In this paper, $4^{th}$ order cardinal B-spline scaling and wavelet functions are used, resulting in  $8^{th}$ and $12^{th}$ order B-spline functions when calculating Eq.~\eqref{eq:Lambdax} and Eq.~\eqref{eq:Uij} respectively  whose values at integer points are given in Table~\ref{table:MRA-BsplineatIntegerPoints}.
\subsection{Frequency Analysis}\label{sec:freq_anal}
To determine the number of basis functions required to reconstruct the field and the level of approximation in the model, $j$, the frequency response of the B-spline wavelets is required. This is given by (see~\ref{ap:FourierofBsplines}) 
\begin{align}      
	  \mathcal{F}(\varphi_{m}\left(r\right)) &=\frac{1}{2}\left(\frac{1-\mathrm{exp}(-\pi i \nu)}{\pi i\nu}\right)^m~\sum_{n=0}^{3m-2}  q_n \mathrm{exp}(-\pi in\nu),\label{eq:MRA-Wavelettransform}
\end{align}
where $\nu$ is the spatial frequency and $i=\sqrt{-1}$. From Eq.~\eqref{eq:MRA-Wavelettransform}, the frequency response of the wavelets and hence the level of approximation, $j$, can be determined. In this way, we choose wavelets up to level $j$ that can fully describe the spatial frequency contents of the underlying dynamics from the observed field.
\section{State and Parameter Estimation}
The aim of this section is to describe the joint state-parameter estimation method used in this study, the expectation maximization (EM) algorithm. Here we provide a general description of the algorithm and also discuss the specific formulation for MRAIDE framework. 

There exist many variations of state and parameter estimation methods for state-space models. The choice of algorithm is normally determined by the dimension of the system, whether the system is linear or nonlinear and whether or not the parameters are considered static or dynamic. Up to this point of the paper, we have not made any assumptions on any of these criteria for choosing an estimation algorithm. The MRAIDE neural field model formulation may be used in any of the above scenarios.

% To demonstrate the MRAIDE estimation framework we shall consider the parameters to be static and we shall also assume that the relationship between the mean membrane potential and the mean firing rate is predominantly linear. Note that there is a difference between forward and inverse modeling when making these assumptions. For example, by using a linear activation function in the estimator we are not assuming that there is necessarily a linear relationship between the membrane voltage and firing rate, but that the statistics of the neural masses fall within a linear operating region over the estimation time period. The major benefit of modeling the relationship between the mean membrane potential and firing rate is the ability to apply the EM algorithm. The loss in model accuracy may be offset estimation accuracy. 

% The simplifications used in formulating the equations enable the development of new methods for extracting information from electrophysiological data. The trade-off between parsimony and complexity is always difficult when considering neurodynamics and this is further complicated when using estimation algorithms that have huge computational demands with such high-dimensional systems.

Nevertheless, when describing a system, a choice needs to be made regarding the complexity of the mathematical description to be adopted. Such a choice is usually based on the principle of parsimony \citep{burnham2002}, that is; choosing the simplest model capable of capturing the system behavior of interest. Such a choice in favour of a simpler model has the added advantages of a smaller parameter space and therefore more accurate estimates and computationally efficient methods.

To demonstrate the MRAIDE estimation framework we shall consider the parameters to be static and we shall also assume that the relationship between the mean membrane potential and the mean firing rate is predominantly linear. Note that by using a linear activation function in the estimator we are not assuming that there is necessarily a linear relationship between the membrane voltage and firing rate, but that the statistics of the neural masses fall within a linear operating region over the estimation time period. This allows for the adoption of the EM algorithm and thus results in computationally efficient and accurate estimates. Consequently, any loss in model detail may be offset by the estimation accuracy.

By assuming a linear activation function of the form
\begin{equation}
	f(v_t(\mathbf{r})) = \varsigma v_t(\mathbf{r}),
\end{equation}
the state transition equation~\eqref{eq:ApproxDiscreteTimeModel4} simplifies to
\begin{equation}\label{eq:ApproxDiscreteTimeModel_Linear}
	\mathbf{x}_{t+1} = 
	\xi \mathbf{x}_t + 
	\varsigma T_s \mathbf{\Lambda}_{x}^{-1} \int_{\Omega}\boldsymbol\mu\left(\mathbf{r}\right)\int_\Omega { 
	    \boldsymbol\theta^\top\boldsymbol\lambda\left(\mathbf{r}-\mathbf{r}'\right)
	    \boldsymbol\mu^\top\left(\mathbf{r}'\right) 
	\, \mathrm{d}\mathbf{r}'\mathrm{d}\mathbf{r}} \mathbf{x}_t
	+ \mathbf{w}_t.
\end{equation}
Now we can further simplify the system by defining
\begin{align}
	\label{eq:Lambdatheta}
	 \mathbf{\Lambda}_{\theta} &\triangleq \int_{\Omega}\boldsymbol\mu\left(r\right) \int_\Omega { 
		   \boldsymbol\theta^\top\boldsymbol\lambda\left(r-r'\right)
		    \boldsymbol\mu^\top\left(r\right)\ \mathrm{d}r'\mathrm{d}r},
\end{align}
to give the state equation
\begin{equation}\label{eq:StateEquation}
 \mathbf x_{t+1} =\mathbf A(\boldsymbol \theta) \mathbf x_t+ \mathbf w_t,
\end{equation} 
with the parameterized transition matrix
\begin{equation}\label{eq:A_theta}
 \mathbf A(\boldsymbol \theta)= T_s\varsigma\mathbf{\Lambda}_{x}^{-1}\mathbf{\Lambda}_{\theta}+\xi\mathbf I.
\end{equation} 
The problem of joint state and parameter estimation for the state-space model given by Eq.~\eqref{eq:ReducedObservationEquation} and Eq.~\eqref{eq:StateEquation}  can now be formulated as 
\begin{equation}
	{\hat{\mathbf X},\hat{\boldsymbol\theta}}=\arg\max_{\mathbf X,\boldsymbol\theta}p(\mathbf Y;\boldsymbol\theta),
 \end{equation}  
where $\mathbf X$ and $\mathbf Y$ denote the entire sequences of the states and observations respectively, $\boldsymbol\theta$ is the parameter set and $p(\mathbf Y;\boldsymbol\theta)$ denotes the probability density function of the observations parameterized  by $\boldsymbol\theta$, known as the likelihood function. This dual estimation problem cannot be solved separately, as for the state estimation the knowledge of the system's parameters is required and for the parameter estimation the states of the system need to be known. One approach is to iteratively estimate the states and parameters of the system and monitor the convergence of the algorithm. A natural framework to perform this is the well known EM algorithm \citep{Dempster1977,Shumway2000} to infer both the parameter set and the states from the observations corresponding to the connectivity kernel, the neural field and electrophysiological data in our application. The EM algorithm is applicable  in two main situations:  first is when the observations are incomplete due to a faulty observation process or existing limitations, and the second is when the direct maximization of the likelihood function is difficult but can be simplified by assuming the existence of an additional data referred to as hidden data \citep{Bilmes1998}, which are the weights of the field basis functions in this case. The EM algorithm, when used in the latter context \citep{Dewar2009}, yields the maximum likelihood kernel estimate, i.e.
\begin{equation}
	\boldsymbol\theta_{\text{ML}}=\arg\max_{\boldsymbol\theta}~p(\mathbf Y;\boldsymbol\theta),
 \end{equation}   
and the posterior distribution of the field over time.

Both the E and the M steps of the EM algorithm find increasingly tighter lower bounds on the likelihood of the parameters so that, at convergence, the maximum of the bound corresponds to the maximum of the likelihood. For state-space models, the E-step corresponds to the smoothing problem \citep{Haykin2001}, which can be solved using the Rauch Tung Streibel (RTS) smoother \citep{RAUCH1965}. For the M-step, a lower bound on the likelihood function is constructed, where the steps needed
to compute the required quantities are very dependent on the particular application. This will be described in detail for our problem. 

In summary, to solve the joint state and parameter estimation for linear state-space models one can adapt the EM algorithm, solving the smoothing problem for the E-step and constructing and maximizing the lower bound in the M-step. A schematic representation of the EM algorithm is represented in Fig.~\ref{fig:EMBlockDiagram}. Note the algorithm can be initialized by either a random parameter set or a sequence of the random bounded state vectors. Here the latter is chosen as shown in the block diagram ensuring the resultant initial kernel estimate leads to a stable system.  
\subsection{E-Step}
As mentioned earlier, the E-step for state-space models is equivalent to the smoothing problem. We use the RTS smoother, given in Table~\ref{alg:MRA-RTS} for completeness, in order to infer the states of the system. The RTS smoother uses the Kalman filter \citep{Kalman1960} in forward pass (Steps~1 and 2 in Table~\ref{alg:MRA-RTS}), along with a backward iteration to calculate its outputs (Steps~3 and 4 in Table~\ref{alg:MRA-RTS}): smoothed states $\hat{\mathbf x}^b_t$ and covariances, $\mathbf P^b_t=\mathrm{cov}(\mathbf{x}_t)$. Following \cite{Gibsona2005}, an additional backwards recursion is also included (Step~5 in Table~\ref{alg:MRA-RTS})	to calculate cross-covariance matrix, $\mathbf M_t=\mathrm{cov}(\mathbf{x}_{t},\mathbf{x}_{t+1})$, which is also required in forming the lower bound on the likelihood function. Note that the following quantities from the forward iteration should be stored when the RTS smoother is implemented: predicted and corrected estimates for both state estimates ($\hat{\mathbf{x}}_t^{f-}$, $\hat{\mathbf{x}}_t^{f}$) and covariance matrices ($\mathbf P_t^{f-}$,$\mathbf P_t^f$). Also, the final value of the Kalman gain, $\mathcal K_T$, should be stored in order to initialize the backward cross-covariance computation. 
 \subsection{M-Step}
The lower bound on the log-likelihood function is given by the expectation of the complete (hidden and observable) data  log-likelihood \citep{Bishop2006} 
\begin{equation}\label{eq:Bishopbound}
	\mathcal Q(\boldsymbol \theta,\boldsymbol\theta')= \mathbf E_{\boldsymbol \theta'}\left[2\ln p(\mathbf X,\mathbf Y;\boldsymbol \theta)\right], 
\end{equation}
where $p(\mathbf X,\mathbf Y;\boldsymbol \theta)$ is the joint probability distribution of the states and the observations and $ \mathbf E_{\boldsymbol \theta'}\left[\cdot\right] $ denotes expectation taken with respect to the marginal distribution of the states conditioned on the observed field and the current estimate of the parameter set, $\boldsymbol\theta'$ i.e.  $p(\mathbf X\mid\mathbf Y;\boldsymbol \theta'$). Note that $p(\mathbf X\mid\mathbf Y;\boldsymbol \theta'$), is in fact the smoother output which is obtained at the E-step.

For the linear state-space model given by Eqs.~\eqref{eq:ReducedObservationEquation} and \eqref{eq:StateEquation}, the bound defined by Eq.~\eqref{eq:Bishopbound} is a quadratic of the form (see \ref{ap:QDerivation} for derivation) 
\begin{equation}\label{eq:MRA-QCompact}
\mathcal Q\left(\boldsymbol \theta,\boldsymbol\theta'\right)=\beta+2T_s\varsigma\left(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1\right)\boldsymbol\theta-T_s\varsigma\boldsymbol\theta^\top\boldsymbol\Upsilon\boldsymbol\theta,
\end{equation}
where $\beta$ is constant with respect to $\boldsymbol\theta$. Equation~\eqref{eq:MRA-QCompact} is maximum at
\begin{align}\label{eq:MRA-thetahat}
\boldsymbol \theta= \boldsymbol\Upsilon^{-\top}(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1)^\top,
\end{align}
where
\begin{align}
\boldsymbol\upsilon_0&=\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_0]_{i,j}[\boldsymbol\Gamma_1]_{j,i}\label{eq:epsilon0} \\
\boldsymbol\upsilon_1&=\xi\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_1]_{i,j}[\boldsymbol\Gamma_1]^{j,i} \label{eq:epsilon1}\\
\boldsymbol\Upsilon&=T_s\varsigma\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_1]_{i,j}[\boldsymbol\Gamma_2]^{j,i},\label{eq:Epsilon}
\end{align} 
and $[\cdot]_{p,q}$ denotes the $\left(p,q\right)$-element of the matrix, $ [\cdot]^{p,q}$ denotes the $\left(p,q\right)$-block of the block matrix and where 
\begin{align}
\left[ \Gamma_1\right]^{j,i} &=\sum_{k=1}^{n_x}\left[ \boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\right]_{jk} \left[ \mathbf U\right]^{k,i},\\
\left[ \Gamma_2\right] ^{j,i}&=\sum_{k,m=1}^{n_x}[\mathbf U^{\top}]^{jk} \left[\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{km}[\mathbf U]^{mi}.
\end{align}
Each $ 1 \times n_{\theta}$ block of the $n_x \times n_x n_{\theta}$ block matrix $\mathbf U$ is 
\begin{align}\label{eq:Uij}
\left[ \mathbf U\right] ^{k,i}&=\int_{\boldsymbol \Omega}\left[\boldsymbol\mu(r) \right]_k \left[\int_{\boldsymbol\Omega} \boldsymbol\mu\left(r'\right)\boldsymbol \lambda^\top \left(r-r'\right) \mathrm{d}r'\right]_{i:} \mathrm{d}r,
\end{align}
where $\left[\cdot\right]_k$ denotes the $k^{th}$ element of the vector and $[\cdot]_{i:} $ denotes the $i^{th}$ row. The matrices $\boldsymbol\Xi_0$ and $\boldsymbol\Xi_1$ in Eqs.~\eqref{eq:epsilon0}-\eqref{eq:Epsilon} are calculated using the RTS smoother outputs: $\hat{\mathbf x}_t^b$, covariance, $\mathbf P_t^b$, and cross-covariance matrix, $\mathbf M_t$ \citep{Gibsona2005} (see \ref{ap:Xiderivation} for details), 
\begin{align}
\boldsymbol\Xi_0&=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t^b\mathbf{\hat x}_{t+1}^{b\top}\right) \label{eq:Xi0} \\
 \boldsymbol\Xi_1&=\sum_{t=0}^{T-1}\left(\mathbf P_t^b+\mathbf{\hat x}_t^b\mathbf{\hat x}_t^{b\top}\right).  \label{eq:Xi1}
\end{align} 
The algorithm has two steps: the E-step, which computes $\boldsymbol\Xi_0$ and $\boldsymbol\Xi_1$ based on the most recent parameter estimates using the RTS smoother, and the M-step, which updates the parameter estimates by computing the (analytic) maximum of $Q(\boldsymbol\theta,\boldsymbol\theta')$. The EM algorithm iterates between these two steps until the parameter estimates converge. A summary of the joint state parameter estimation is given in Table~\ref{alg:EMsteps}.   
\subsection{Stopping Rule}
The stopping criterion is usually associated with either the change in the parameter estimates or the log-likelihood variation \citep{McLachlan1997}. The stopping rule adopted herein is
\begin{equation}
 \left(\parallel \mathbf{A} \parallel_{F}^{(i)}-\parallel \mathbf{A} \parallel_{F}^{(i-1)}\right)<\epsilon,
 \end{equation}
 where $\epsilon$ is a threshold value and $\parallel \mathbf{A} \parallel_{F}^{(i)}$ and $ \parallel \mathbf{A} \parallel_{F}^{(i-1)}$ are the Frobenius norms  of the successive estimates of $\mathbf{A} $ matrices which is defined by \citet{Meyer2000}
 \begin{equation}
  \parallel \mathbf{A} \parallel_{F}=\sqrt{\sum_{i,j=1}^{n_x}\mid a_{i,j} \mid^2}=\sqrt{\mathrm{tr} (\mathbf A^{\top}\mathbf A)}.
 \end{equation}
\subsection{Computational Complexity} 
All $n_x^2$ blocks of $\mathbf U$, $\boldsymbol\Gamma_1$ and $\boldsymbol\Gamma_2$  can be computed as a one-off before the commencement of the EM iterations (Step~1 in Table~\ref{alg:EMsteps} ), which increases the speed of the M-step significantly compared to the implementation of \citet{Dewar2009}. The complexity of each step of the algorithm is summarized in Table~\ref{table:MRA-ComputationalComplexity} where for ease of comparison the computational complexity of the method of \citet{Dewar2009} is also identified. It can be seen from the table that the state dimension is an important factor at each iteration of the estimation algorithm, emphasizing the advantage of the proposed algorithm compared to the method proposed in \citet{Dewar2009}. This also suggests the use of an efficient algorithm to choose the minimum number of basis functions (states of the system) while achieving the desired details of the underlying field.  
\section{Results}\label{sec:MRA-results}
To demonstrate the performance of the MRAIDE estimation framework, data was generated synthetically \parham{using Amari neural field model  (Eqs.~\eqref{eq:DiscreteTimeModel} and \eqref{eq:ObservationEquation})}, allowing a comparison between true and estimated parameters \footnote{\parham{The Python source code for our numerical simulations is available from the authors on request.}}. In doing so, the membrane time constant was set to $\tau = 10$~ms \citep{David2003}, and the sampling time was chosen ten times faster \citep{Stephan2008}, i.e. $T_s = 1$~ms, ensuring the discrepancy between the continuous neural field model and its discrete approximation is small. The connectivity kernel used for data generation composed of two B-spline scaling functions at $j=0$ and $j=1$ forming a compact support Mexican hat shape 
\begin{equation}\label{eq:ConnectivityKernelForData}
	w(r-r')=\theta_1\times N_{4;1,2}(r-r')+\theta_2\times N_{4;0,2}(r-r'),
\end{equation}
with $\theta_1=200$ and $\theta_2=-100$. 
% This is depicted in Fig.~\ref{fig:KernelEstimate}(A).

Two different experiments were designed to test the framework. In the first one, 200 realizations of 1 second of data were used, where the field disturbance, $e_t$, and the observation noise, $\boldsymbol\epsilon_t$, were regenerated each run. This way the net shape of the connectivity kernel could be formed by averaging over the parameters estimates from each realization. In the second experiment, a single data set was generated and the field estimations are compared for five state-space models, each accounting up to a certain level of approximation, i.e. $j=0$ to $j=4$. \parham{We show it is possible to determine the level of approximation to accurately estimate the underlying field prior to the EM-based algorithm.} All parameters for the model are given in Table~\ref{tab:Parameters}.

For each of the experiments, the estimation was applied to the final 900~ms, allowing the forward model's dynamics to stabilize from the initial conditions. The initial state, parameters and the support of the connectivity kernel were unknown to the estimator. The observation noise was set to $\boldsymbol\Sigma_{\epsilon}=0.1 \times \mathbf{I}_{n_y}$ and the disturbance covariance function was set to $\eta(r-r') = \sigma_d\times\varphi_{4;3,2}(r-r')$ (B-spline, $j=3$) with $\sigma_d=0.53$.  The firing rate slope, $\varsigma$ was set to $0.56~mV^{-1}$ \citep{Wendling2005}. The observation kernel was modeled using a B-spline function, with a width of 0.08~mm at half the maximum amplitude where the distance between adjacent sensors was $0.05$~mm, resulting into $n_y = 161$ observations. The choice of B-spline function to model the observation kernel is justified by the experiment performed in \citet{Freestone2011}. The spacing and bandwidth of the sensors allowed the full spatial bandwidth of the field to be observed.  With this number of observations, the estimation problem was well-posed, i.e. the number of states, $n_x < n_y$ at each level of the decomposition. This is because the scaling functions are orthogonal to the wavelets at the same and higher levels of decomposition, and  the wavelets are orthogonal to each other across different scales (see Eqs.~\eqref{eq:MRA-PsiPsiOrthogonality} and \eqref{eq:MRA-PhiPsiOrthogonality}).
\subsection{Experiment I}
The spatial frequency response of the observed field was used to specify the level of decomposition required to represent the field using the wavelets. This is shown in Fig.~\ref{fig:ObservationFrequencyResponce} where the graph obtained by averaging the spectral power of the spatial frequency (over time) from the observations \citep{Scerri2009}. The spatial bandwidths of wavelets were calculated analytically using Eq.~\eqref{eq:MRA-Wavelettransform}. The result suggested that wavelets up to level $j=3$ (with the bandwidth $\approx[5,8]$ cycles/mm) can represent the significant spatial characteristics of the field which yields $n_x = 131$ states, corresponding to 9 scaling functions for $j=0$ and 8, 16, 32 and 66 wavelet functions, respectively for $j=0$, $j=1$, $j=2$ and $j=3$. 


The EM algorithm was allowed to run until a maximum number of 20 iterations was reached, though typically the change in the transition matrix Frobenius norm dropped below $10^{-6}$ after less than 10 iterations. The rate of convergence of the EM based algorithm is depicted in Fig.~\ref{fig:MRA-Convergence}. 


The actual connectivity kernel and the decomposition is plotted in Fig.~\ref{fig:KernelEstimate}(A). No assumptions where made about the shape of the kernel. The reconstructed kernel is in good accordance with the actual kernel, where the actual kernel lies inside the confidence interval. The large standard deviation is due to the high number of parameters needed to be estimated. The small error in the estimate is attributed to the MRA of the system used to form the estimator. Figs.~\ref{fig:KernelEstimate}(B) and (C) illustrate the kernel scaling and wavelet functions, respectively. A total number of 25 basis functions were used to reconstruct the kernel, comprising 13 and 12 scaling and wavelet functions at $j=1$, respectively. 

One snap shot of the field reconstruction, at different levels of approximation is given in Fig.~\ref{fig:FieldEstimates100}, showing small discrepancy between the actual and estimated field at $j=3$. From this figure, it can be observed that the overall trend of the underlying field can be also captured at the coarser levels.
\subsection{Experiment II}
To study the performance of different models with various MRA capabilities, a single realization was obtained using Eqs.~\eqref{eq:DiscreteTimeModel} and \eqref{eq:ObservationEquation} under the same circumstances of the previous experiment. The generated data set was then employed to estimate the underlying field and the connectivity kernel parameters using different state-space models, $j=0$ up to $j=4$. The mean over time of the root mean square error (MRMSE) over space of the field estimation for different models is shown in Fig.~\ref{fig:RMSE}. By increasing the value of $j$, error in the estimation decreases and converges to a steady value of 0.71, confirming that the model with $j=3$ (used in the first experiment) is in fact adequate to capture the dynamics of the underlying field. The spatiotemporal characteristics of the reconstructed fields (A-E) along with the actual field (F)  are shown in Fig.~\ref{fig:FieldEstimation}. The experiment was performed several times and the results were consistent over each run.
\section{Discussion}
In this paper, we have presented a novel model-based framework for estimating cortical dynamics from electrophysiological measurements. The novel and key developments of the paper include the multi-resolution finite element model representation of the neural field, and the estimator for an intracortical connectivity kernel with an arbitrary shape. By decomposing both the spatial field and the connectivity kernel using a wavelet decomposition, it becomes possible to represent small scale details in the field at the same time as large scale details. This work is significant, as the ability to create patient-specific neural field models has the potential to contribute to our understanding and improve treatment of diseases resulting from abnormal neurodynamics. Other groups have previously highlighted the importance of a multi-resolution approach in neural field modeling, where the dynamics and connectivity structure differs at different spatial scales~\citep{Jirsa2002,Jirsa2004,Breakspear2005,Qubbaj2009,Schultze-Kraft2011}. 
\subsection{State-Space Representation}
In order to apply estimation algorithms to neural field models a finite-dimensional state-space model must be formed. The problem of representing a continuous field with a finite number of states is solved by the basis function decomposition. An alternative to using the B-spline wavelets are Gaussian basis functions, which were adopted by \cite{Freestone2011} to decompose the field and connectivity kernel. One clear advantage of B-spline scaling and wavelet functions is the MRA capability, allowing the simultaneous representation of the neural field at different spatial scales. B-spline scaling and wavelet functions are compactly supported, eliminating  numerical errors caused by the Gaussian basis function. The partition of unity (ability to represent a zero spatial frequency field) of these basis functions enable the reconstruction of the neural field when it saturates. This may be beneficial to model neurological disorders such as epilepsy. Attaining fine-scale approximation of the neural field using Gaussian basis functions results in an ill-posed problem as the number of states is increased significantly. However, this is not the case when using B-spline scaling and wavelet functions due to their semi-orthogonality property.\\ \citet{Freestone2011} showed experimentally that Gaussian functions are a suitable choice for modeling the observation kernel when intracranial measurements are considered. B-splines converge to Gaussian functions as the order of the B-spline, $m$, tends to infinity. The cubic B-spline is already a very close approximation to the Gaussian function. Therefore, these should also be suitable for modeling the observation kernel while having the advantage of being compactly supported.

\subsection{Estimation Algorithm}
The implementation of the M-step in this work significantly simplifies the computational complexity of the EM based algorithm proposed by \cite{Dewar2009}, as shown in Table~\ref{table:MRA-ComputationalComplexity} ($O(n_x^4n_{\theta}^2)$ to $O(n_x^2n_{\theta}^2)$). This is crucial for high-dimensional systems, and more specifically, for implementing the multi-resolution framework introduced herein. Furthermore, choosing isotropic scaling and wavelet functions allows switching the order of operations with the spatial convolution and inner product in Eq.~\eqref{eq:ApproxDiscreteTimeModel4}. This simplifies the computational complexity of the estimation algorithm significantly.

For a larger space, or in a case where the connectivity kernel decomposition comprises of many scale levels, the number of parameters to be estimated increases significantly. One solution to this problem could be expectation-conditional maximization (ECM) \citep{Meng1993,Meng1994}, which replaces the M-step by a series of computationally simplified conditional maximization (CM) steps. The ECM is a class of generalized EM (GEM) algorithms in which the $\mathcal{Q}$-function is increased rather than being maximized \citep{Fessler1994}. For systems with a high number of states, the ensemble Kalman smoother (EnKS) \citep{Evensen2003,Evensen2009a,Evensen2009} provides an alternative to the RTS smoother used in this work. The EnKS is a sequential Monte Carlo (MC) method where the state covariance matrix is approximated by a large stochastic ensemble of model states, thus alleviating computational load due to the storage and forward integration of the state covariance matrix. However, combining the EnKS with the EM algorithm suffers from the loss of monotonicity property --- increase in the likelihood function--- as MC error will be introduced at the E-step.

Typically, a sequence of likelihood values will converge to a stationary point, i.e. a global (local) maximum or a saddle point. If the sequence of the EM is trapped in a local maximum or a saddle point, a small random perturbation diverges the algorithm from such stationary values \citep{McLachlan1997}. In general, convergence of the EM algorithm to any stationary point depends on the initialization. In the examples presented in this paper, a bounded sequence of the state vectors was used to initialize the algorithm, which gave a satisfactory convergence and good state and parameter estimations. 

\dean{The basis structure (i.e., non-redundant versus a (tight) frame representation) is a requirement for this framework.} 

\subsection{Modification to Higher Dimensions}
The reconstruction of the neural field in higher dimensions requires $2^n-1$ wavelets, where $n$ is the dimension of the space. For example a two-dimensional MRA can be implemented using 2-D scaling and wavelet functions built up using the tensor-product approach \citep{Meyer1992}. In this case three wavelet functions are required to extract fine features of the field at vertical, horizontal and diagonal orientations. Theoretically, the formulations provided in this paper can be easily extended to two dimensions. However, the increase in computational load of the estimation algorithm will be significant. This is not only due to the increase in number of wavelets, but also the switch of convolution and inner product does not hold, as the resulting higher-dimensional B-spline wavelets are not isotropic. A possible solution could be to use  
isotropic polyharmonic B-splines scaling functions and wavelets as an alternative \citep{VanDeVille2005}.

It is important to investigate methods for choosing basis functions to balance the complexity with the reconstruction capability of the model. It is also possible to apply other methods than dyadic subsampling schemes in multiple dimensions, which leads to less wavelet subbands. For example, in 2D, the quincunx scheme is well-known to have better isotropic properties. Unfortunately, in 3D, it is not possible to have a subsampling operator (acting on a Cartesian sampling lattice) that is performing subsampling at equal rate in each dimension at each iteration \citep{VanDeVille2005a}.
\subsection{Extensions to the Framework} 
Clearly there is, and will always be, a discrepancy between the dynamics of the model and the experimental observation. Nevertheless, the model-based framework proposed in this paper may enable meaningful state tracking and connectivity estimation. The MRAIDE approach is not limited to neural fields; the framework can be applied to modeling other multi-resolution spatiotemporal dynamical systems such as weather systems, ecological systems, and others~\citep{Wikle2002,Xu2005}. The key development is the multi-resolution decomposition forming the state-space model. While the decomposition holds for more sophisticated models, efficiently performing nonlinear smoothing in the large state-space remains a challenge.                                                                                                 

Additional extension for future work include extending the model to capture a second order synaptic response kernel. The second-order postsynaptic kernel proposed in \citet{VanRotterdam1982} leads to dynamics that are more reminiscent to real postsynaptic potentials (see \citet{Spiegler2010,Spiegler2011} for example). Another extension of this framework is the inclusion of finite distant-dependent action potential propagation velocity into the parametric neural field equations. In small networks the resulting delays via propagation can be neglected. However, delays must be accounted for in large scale networks. For instance, \citet{Ghosh2008} demonstrated that inclusion of time delays arising from propagation along connecting fibres are essential for the understanding of the fluctuations in resting state networks. Finally, future work should be directed towards applying and validating the framework on real data.                                                                   

% (see \citet{Deco2010} for review) In fact, \citet{Ghosh2008} emphasize that the couplings in large-scale brain networks have a space-time structure composed of their anatomical connectivity (space) and signal transmission delays (time). To capture correctly the constraints posed upon the network dynamics by connectivity, the space-time structure of the brain connectivity must be correctly estimated. 
\section{Acknowledgements}
The research reported herein was partly supported by the Brain Network Recovery Group through the James S. McDonnell Foundation and the FP7-ICT BrainScales. This research was also partly supported by the Australian Research Council (Linkage Project LP100200571). The Bionics Institute acknowledges the support it receives from the Victorian State Government through the Operational Infrastructure Support Program.
\clearpage
\newpage
\section*{Tables}
 \singlespacing
\begin{table*}[!t]
\begin{tabular}{|l|l|l|}
	\hline
	\textbf{Symbol} & \textbf{Quantity} & \textbf{Units}\\
	\hline
	\multicolumn{3}{|c|}{\emph{Domain and indices}}\\
	\hline
	$\Omega$ & Spatial domain & n.a.\\ 
	$\mathbb{R}$&\parham{The set of all real numbers}&n.a.\\
	$\mathbb{Z}$&\parham{The set of all integers}&n.a.\\
	$\mathbf{r}$ & Spatial location & [mm, mm]\\
	$t$ & Time & s\\
	\hline
	\multicolumn{3}{|c|}{\emph{Model}}\\
	\hline
    $y_t$ & Observation & mV\\
    $v(\mathbf{r},t)$ & Mean membrane potential & mV \\
	$f(v\left(\mathbf{r},t\right))$ & Firing rate function & spikes.s$^{-1}$\\
	$e_t(\mathbf{r})$ & Field disturbance, with covariance function $\eta(\mathbf r-\mathbf r')$ & mV\\
	$\boldsymbol\epsilon_t$ & Observation noise, with covariance matrix $\Sigma_\epsilon$ & mV\\
	$m(\mathbf{r}_n)$ & Observation kernel where $n$ is sensor index $n=1,..,n_y$ & n.a. \\
	$w(\mathbf{r})$ & Spatial connectivity kernel & n.a.\\
	$h(t)$ & Post-synaptic response kernel & n.a.\\
	$\tau$, $\xi$ & Membrane time constant \& time constant parameter & s, n.a.\\
	$\delta(t)$ & Dirac-delta function & n.a.\\
	\hline    
	\multicolumn{3}{|c|}{\emph{Multi-resolution Approximation}} \\
	\hline                                                   
	$\phi_{j,l}(r)$&Scaling function&n.a\\
	$\psi_{j,l}(r)$&Wavelet function&n.a\\  
	$a_{j_0,l}, c_{j,l}$&Connectivity kernel approximation and detail coefficients&mV~spike$^{-1}$\\ 
	$x_{t,j_{0},l},\check{x}_{t,j,l}$&Field approximation and detail coefficients at a given time&mV~spike$^{-1}$\\ 
	$N_m(r)$&$m^{th}$ order B-spline function&n.a.\\
	$\varphi_m(r)$&$m^{th}$ order B-spline wavelet function&n.a.\\
	\hline
	\multicolumn{3}{|c|}{\emph{State-Space Model}} \\
	\hline
		$\boldsymbol\mu(r)$&Vector of $n_x$ field scaling and wavelet functions&n.a.\\
		$\boldsymbol\lambda(r)$&Vector of $n_{\boldsymbol\theta}$ connectivity kernel scaling and wavelet functions&n.a.\\
   	$\mathbf{x}_t$ & State vector at time $t$ composed of  $x_{t,j_{0},l}$ and $\check{x}_{t,j,l}$ & mV\\ 
		$\boldsymbol\theta$&Vector of connectivity kernel parameters composed of $a_{j_0,l}$ and $c_{j,l}$& mV.spike$^{-1}$\\ 
		$\boldsymbol{\Lambda}_x$&Inner product of field basis functions&n.a.\\
		$\boldsymbol\Gamma, \boldsymbol\Lambda_{\boldsymbol{\theta}}$&Decomposition connectivity matrices&s, mV.spike$^{-1}$\\
   	$\mathbf{w}_t$ & State disturbance vector, with covariance $\Sigma_w$ & mV\\ 
    $\mathbf{A}(\boldsymbol{\theta})$& State transition matrix& n.a.\\
   	$\mathbf{C}$ & Observation matrix & n.a. \\
	\hline
	\multicolumn{3}{|c|}{\emph{Frequency Analysis}} \\
	\hline
	$\boldsymbol{\nu}$& spatial frequency  & cycles/mm \\
	\hline
	\multicolumn{3}{|c|}{\emph{Estimation}} \\
	\hline
	$\hat{\mathbf{x}}_t^{f-}$, $\hat{\mathbf{x}}_t^f$ & Forward prior and posterior state estimates & mV\\
	$\hat{\mathbf{x}}_t^{b}$ & Backward posterior state estimates & mV\\
	$\mathbf P^{f-}_t$, $\mathbf P^f_t$  & Forward prior and posterior covariance matrices & mV$^2$\\
	$\mathbf P^b_t$ & Backward posterior covariance matrices & mV$^2$\\
	$\mathbf M_t$& Cross-covariance matrix & mV$^2$\\
	$\mathcal K_{t} $ & Filter gain & n.a.\\ 
	$\mathcal S_{t} $ & Smoother gain & n.a.\\ 
	$\boldsymbol\Xi_1, \boldsymbol\Xi_0$&Expected covariance and cross-covariance matrices& mV$^2$\\ 
	$\mathcal{Q}(\boldsymbol{\theta},\boldsymbol\theta')$&Lower bound on log-likelihood function&n.a.\\
	$\boldsymbol\nu_0$, $\boldsymbol\nu_1$&Lower bound coefficient matrices&n.a.\\ 
	$\boldsymbol\Upsilon$&Lower bound coefficient matrix&mV$^{-1}$.spike\\
	\hline
\end{tabular}
\caption{\textbf{Notation.} The first column of the table gives the symbols for all the notation used in the paper. The second column provides a brief description of the quantity, and the third column provides the SI units where relevant.}
\label{tab:Notation}
\end{table*}  
\doublespacing
\clearpage
\newpage
\begin {table}[t]
\begin{center}
	\begin{tabular}{lcccc}
	\hline \hline
	& $k$ & $3!N_{4}\left(k\right)$ & $7!N_{8}\left(k\right)$ & $11!N_{12}\left(k\right)$\\ 
	\hline 
	& 1 & $1$ & $1$ & $1$\\
	& 2 & $4$ & $120$ & $2,036$\\
	& 3 & $\space$ & $1,191$ & $152,637$\\
	& 4 & $\space$ & $2,416$ & $2,203,488$\\
	& 5 & $\space$ & $\space$ & $9,738,114$\\
	& 6 & $\space$ & $\space$ & $15,724,248$\\
	\hline \hline
	\end{tabular}
 \caption {{\bf Cardinal B-Splines at the knot sequence}. Table entries are calculated using Eq.~\eqref{eq:MRA-recursiveBsplineatintegerpoints} and can be also found in \citet{Goswami1999}.} 
 \label{table:MRA-BsplineatIntegerPoints}
 \end{center}
 \end {table}
\clearpage
\newpage 
\renewcommand{\arraystretch}{1.7}
\begin{table*}[!ht]
\begin{tabular}{|c|}\hline
\multicolumn{1}{|p{16cm}|}{\textbf{1.} Forward initialization} \\ 
$\hat{\mathbf x}_0, \mathbf P_0$ \\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{2.} Forward iteration: for $t\in\left\lbrace 0,\cdots,T-1\right\rbrace $, calculate the predicted state and the predicted covariance matrix } \\
$\hat{\mathbf x}_{t+1}^{f-}=\mathbf A \hat{\mathbf x}_{t}^{f}$  \\ 
$\mathbf P_{t+1}^{f-}=\mathbf A \mathbf P_{t}^{f}\mathbf A^{\top}+\boldsymbol\Sigma_e$  \\
\multicolumn{1}{|p{16cm}|}{compute the filter gain, the filtered state and the filtered covariance matrix} \\
$\mathcal K_{t+1}=\mathbf P_{t +1}^{f-}\mathbf C ^\top(\mathbf C \mathbf P_{t +1}^{f-}\mathbf C ^\top+\boldsymbol \Sigma_{\varepsilon})^{-1}$\\
$\hat{\mathbf x}_{t+1}^{f}=\hat{\mathbf x}_{t+1}^{f-}+\mathcal K_{t+1}(\mathbf y_{t+1}-\mathbf C\hat{\mathbf x}_{t +1}^{f-})$\\
$\mathbf P_{t+1}^f=(\mathbf I - \mathcal K_{t+1}\mathbf C)\mathbf P_{t +1}^{f-}$\\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{3.} Backward initialization}\\
 $\mathbf P_T^b= \mathbf P_T^f, \quad \hat{\mathbf x}^b_T= \hat{\mathbf x}^f_T$\\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{4.} Backward iteration: for $t\in\left\lbrace T-1,\cdots,0\right\rbrace $ compute the smoother gain, the smoothed state and the smoothed covariance matrix}\\  
$\mathcal S_{t}=\mathbf P_{t}^{f}\mathbf A^{\top}\left[ \mathbf P_{t +1}^{f-}\right]^{-1}$ \\
 $\hat{\mathbf x}_t^b=\hat{\mathbf x}_t^f+\mathcal S_t(\hat{\mathbf x}_{t+1}^{b}-\hat{\mathbf x}_{t+1}^{f-})$ \\
 $\mathbf P_{t}^{b}=\mathbf P_{t}^{f}+\mathcal S_t(\mathbf P_{t+1}^{b}-\mathbf P_{t+1}^{f-})\mathcal S_t^\top$\\  
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{5.} Compute the smoothed cross covariance matrix, initialization}\\
$\mathbf M_T=(\mathbf I-\mathcal K_T\mathbf C)\mathbf A\mathbf P_{T-1}^b$\\
\multicolumn{1}{|p{16cm}|}{for $t\in\left\lbrace T-1,\cdots,1\right\rbrace $ compute}\\
$\mathbf M_t= \mathbf P_t^{f}\mathcal S_{t-1}^{\top}+\mathcal S_{t}(\mathbf M_{t+1}-\mathbf A\mathbf P_t^{f} )\mathcal S_{t-1}^{\top}$\\
\hline
\end{tabular}
\caption{\textbf{Algorithm for the RTS smoother (E-step).} This table shows the steps in the  Rauch-Tung-Striebel smoother algorithm.}
\label{alg:MRA-RTS}
\end{table*}
\renewcommand{\arraystretch}{1}  
\clearpage
\newpage
\begin {table}
\begin{center}
\scalebox{1}{\begin{tabular}{lllc}
\hline \hline
Variable &Equation&Order&Order obtained from \citet{Dewar2009}\\ \hline\\
$\Xi_0, \Xi_1$&Eqs.~\eqref{eq:Xi0} and \eqref{eq:Xi1}&$O(Tn_x^2)$& \----\\
$\boldsymbol\upsilon_0, \boldsymbol\upsilon_1$&Eqs.~\eqref{eq:epsilon0} and \eqref{eq:epsilon1} &$O(n_x^2n_{\theta})$ &$O(n_x^2n_{\theta})+O(n_x^3)$ \\
$\boldsymbol\Upsilon$&Eq.~\eqref{eq:Epsilon}&$O(n_x^2n_{\theta}^2)$&$O(n_x^4n_{\theta}^2)$\\
$\mathbf A(\boldsymbol\theta)$&Eq.~\eqref{eq:A_theta}&$O(n_x^3)$&\----\\
$\boldsymbol\Lambda_{\theta}$&Eq.~\eqref{eq:LambdaThetaElements}&$O(n_x^2n_{\theta})$&\----\\
$\hat{\boldsymbol\theta} $&Eq.~\eqref{eq:MRA-thetahat}&$O(n_{\theta}^3)$&\----\\
\hline \hline
\end{tabular}}
 \caption {{\bf The Computational complexity of the estimation algorithm}. A comparison between the algorithm proposed herein and that of \citet{Dewar2009} is also provided. "\----'' indicate equal complexities for both algorithms.} 
\label{table:MRA-ComputationalComplexity}
\end{center}
\end {table} 
\clearpage
\newpage
\renewcommand{\arraystretch}{1.7}
\begin{table*}[!ht]
\begin{tabular}{|c|}\hline
\multicolumn{1}{|p{16cm}|}{\textbf{1.} Initialization:  } \\ 
\multicolumn{1}{|p{16cm}|}{Choose a bounded random state vector sequence $\hat{\mathbf X}$, and set $\mathbf P_t$ and $\mathbf M_t$ large} \\
\multicolumn{1}{|p{16cm}|}{compute} \\
$\mathbf{\Lambda}_{x}=\int_{\Omega}\boldsymbol{\mu}\left(r\right)\boldsymbol{\mu}^\top\left(r\right) \mathrm{d}r$\\
\multicolumn{1}{|p{16cm}|}{compute all the $n^2_x$ blocks of block matrices $\mathbf U$, $\Gamma_1$ and  $\Gamma_2$ using} \\
$\left[ \mathbf U\right] ^{k,i}=\int_{\boldsymbol \Omega}\left[\boldsymbol\mu(r) \right]_k \left[\int_{\boldsymbol\Omega} \boldsymbol\mu\left(r'\right)\boldsymbol \lambda^\top \left(r-r'\right) dr'\right]_{i:} dr$\\
$\left[ \Gamma_1\right]^{j,i} =\sum_{k=1}^{n_x}\left[ \boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\right]_{jk} \left[ \mathbf U\right]^{k,i}$\\
$\left[ \Gamma_2\right] ^{j,i}=\sum_{k,m=1}^{n_x}[\mathbf U^{\top}]^{jk} \left[\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{km}[\mathbf U]^{mi}$\\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{2.} Estimate the connectivity kernel parameters} \\
$\boldsymbol\Xi_0=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t\mathbf{\hat x}_{t+1}^\top\right)$\\
$\boldsymbol\Xi_1=\sum_{t=0}^{T-1}\left(\mathbf P_t+\mathbf{\hat x}_t\mathbf{\hat x}_t^\top\right)$\\
$\boldsymbol\upsilon_0=\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_0]_{i,j}[\boldsymbol\Gamma_1]_{j,i}$\\
$\boldsymbol\upsilon_1=\xi\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_1]_{i,j}[\boldsymbol\Gamma_1]^{j,i}$\\
$\boldsymbol\Upsilon=T_s\varsigma\sum_{i,j=1}^{n_x}[\boldsymbol\Xi_1]_{i,j}[\boldsymbol\Gamma_2]^{j,i}$\\
$\boldsymbol \theta= \boldsymbol\Upsilon^{-\top}(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1)^\top$\\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{3.} Form a state-space representation}\\
\multicolumn{1}{|p{16cm}|}{compute all $n_x^2$ elements of $\boldsymbol\Lambda_{\theta}$ using} \\
$\left[ \boldsymbol\Lambda_{\theta}\right] _{k,i}=\left[ \mathbf U\right]^{k,i}\boldsymbol\theta$\\
\multicolumn{1}{|p{16cm}|}{compute transition matrix $\mathbf A(\boldsymbol\theta)$ } \\
$\mathbf A(\boldsymbol \theta) = T_s\varsigma\mathbf{\Lambda}_{x}^{-1}\mathbf{\Lambda}_{\theta}+\xi\mathbf I$\\
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{4.} Compute the smoothed state $\hat{\mathbf x}_t^b$, the smoothed covariance, $\mathbf P^b_t$ and cross-covariance, $\mathbf M_t$ for $t\in\left\lbrace 0,\cdots,T\right\rbrace $ using the RTS smoother given in Table~\ref{alg:MRA-RTS}.}\\  
\hline
\multicolumn{1}{|p{16cm}|}{\textbf{5.} Convergence: return to Step~2 unless }\\
$ \left(\parallel \mathbf{A} \parallel_{F}^{(i)}-\parallel \mathbf{A} \parallel_{F}^{(i-1)}\right)<\epsilon$\\
\hline
\end{tabular}
\caption{\textbf{State and parameter estimation for the MRAIDE model.} This table shows the steps for the joint state and parameter estimation using the EM based algorithm.}
\label{alg:EMsteps}
\end{table*}
\renewcommand{\arraystretch}{1}
\clearpage
\newpage 
\begin{table*}[!ht]
\begin{tabular}{|c|l|c|l|}
	\hline
	\textbf{Symbol} & \textbf{Quantity} & \textbf{Value} & \textbf{Units}\\
	\hline
	\multicolumn{4}{|c|}{\emph{Domain and indices}}\\
	\hline
	$\Delta$ & Spatial discretisation step & 0.01 & mm \\
	$T_s$ & Time step & $0.001$ & s\\
	$T$ & Number of time steps used in estimation & 900 & n.a.\\
	\hline 
\multicolumn{4}{|c|}{\emph{Model}}\\
	\hline
	$\tau$ & Membrane time constant & 0.01 & s$^{-1}$ \\
	$\varsigma$ & Slope of activation function & 0.56 \citep{Wendling2005} & mV$^{-1}$.spike.s$^{-1}$\\
	$\boldsymbol{\theta}$ & Vector of connectivity kernel parameters (data generation) & $\left[\begin{array}{cc}
	200 & -100
	\end{array}
	\right]^{\top}$ & mV.spike$^{-1}$\\
	$n_y$ & Number of sensors & 161 & n.a.\\ 
	$\Delta_y$ & Distance between adjacent sensors & 0.05 & mm\\
	$\sigma_{m}$ & Observation kernel full width at half maximum & 0.08 & mm \\
	$\Sigma_{\varepsilon}$ & Observation noise covariance matrix & $0.1 \times I_{n_y}$ & mm$^2$ \\
	$\sigma_{\eta}$& Disturbance covariance function full width at half maximum & 0.18 & mm\\
	$\sigma_{d}$ & Disturbance variance & 0.53 & mV \\
	\hline 
	\multicolumn{4}{|c|}{\emph{Reduced Model}}\\
	\hline
	$n_x$ & Number of field basis functions&& n.a.\\
	$   $ &Experiment~I, $j=3$&131&\\
	$   $ &Experiment~II, $j=0,1,2,3,4$&17, 33, 65, 131, 263&\\ 
	\hline 
	\multicolumn{4}{|c|}{\emph{Estimation}}\\ 
	\hline
	$n_{\theta}$&Number of connectivity kernel basis functions for estimation&25&n.a.\\
	\hline 
\end{tabular}
\caption{\textbf{Parameters.} Parameters for the neural field model and the reduced model and the estimation procedure.}
\label{tab:Parameters}
\end{table*}   
\newpage
\clearpage
\section*{Figure Legends}
{\bf Figure 1. Multi-layer neural field structure}. The inset figures show the shape of the
connectivity kernel components at each spatial resolution.

{\bf Figure 2. The IDE neural field model components}. (\textbf{A}) The Mexican hat (solid line) and Wizard hat (dotted line) connectivity kernels composed of Gaussian and Laplacian basis functions respectively. (\textbf{B}) First order (dotted line) and second order (solid line) synaptic kernels. (\textbf{C}) The sigmoidal (solid line) and the Heaviside (dotted line) activation functions.   

{\bf Figure 3. Examples of cardinal B-spline functions}. Piecewise polynomial functions (dotted lines) are joined at the break points (black circles). (\textbf{A}) B-spline function of order 2 (linear B-spline). (\textbf{B}) B-spline function of order 8.

{\bf Figure 4. Examples of B-spline scaling and wavelet functions}. (\textbf{A}) The cubic B-spline scaling function. (\textbf{B}) The corresponding wavelet function.

{\bf Figure 5. Schematic of the EM algorithm}. The RTS smoother (E-step) and the maximization of the lower bound, $\mathcal Q(\boldsymbol \theta,\boldsymbol\theta')$, (M-step) are shown. The dashed box shows the iterative two step algorithm once it is initialized.

{\bf Figure 6. Spatial frequency analysis}. The average (over time) power in dB of the spatial frequency of the observations. 

{\bf Figure 7. Convergence of the EM based algorithm}. The mean  of the $\mathbf A(\boldsymbol\theta)$ Frobenius norm over 200 realizations vs iterations of the EM based algorithm. The change in the stopping criterion falls below $10^{-6}$ after less than 10 iterations.  

{\bf Figure 8. Connectivity kernel estimate}. (\textbf{A}) The actual kernel and its components are shown by solid and dashed black lines, respectively. The mean kernel estimates over 200 realizations and confidence interval are shown by the red line and red shaded region ($\pm2$ std.). (\textbf{B},\textbf{C}) Kernel scaling and wavelets functions, respectively, at $j=1$ used in the estimation algorithm. 

{\bf Figure 9. Examples of the actual and estimated neural fields for experiment I}. Actual (grey) and estimated (black) neural fields at a single time instant for different spatial resolutions. (\textbf{A}) $j=0$, $n_x=17$. (\textbf{B}) $j=1$, $n_x=33$. (\textbf{C}) $j=2$, $n_x=65$. (\textbf{D}) $j=3$, $n_x=131$.

{\bf Figure 10. Error in the field reconstruction for experiment II}. The mean (over time) of average (over space) RMSE of the estimated field of state-space models with different MRA capabilities. $j=0$, $RMSE = 1.83$; $j=1$, $RMSE = 1.41$; $j=2$, $RMSE = 0.83$; $j=3$, $RMSE = 0.71$; $j=4$, $RMSE=0.71$ 

{\bf Figure 11. Actual and estimated spatiotemporal neural field using state-space models with different MRA capabilities}. (\textbf{A}) The reconstructed field of the reduced model using wavelet upto $j=0$ with $n_x=17$. (\textbf{B}) The reconstructed field using wavelets upto $j=1$ with $n_x=33$. (\textbf{C}) The reconstructed field  using wavelets upto $j=2$ with $n_x=65$. (\textbf{D}) The reconstructed field using wavelets upto $j=3$ with $n_x=131$. (\textbf{E}) The reconstructed field using wavelets upto $j=4$ with $n_x=263$. (\textbf{F}) The actual field. 
  \clearpage
   \newpage 
   \begin{figure}[t]
   		\includegraphics[scale=1]{Graph/fig1.pdf}
   	\caption{}
   	\label{fig:MultiLayerFieldModel}
   \end{figure}  
 \clearpage
  \newpage 
  \begin{figure}[!t]
  \centering
  \includegraphics[scale=1]{Graph/fig2.pdf}
  \caption{}
  \label{fig:Modelcomponents}
  \end{figure}
  \clearpage
  \newpage  
  \begin{figure}[!t]
  \centering
  \includegraphics{Graph/fig3.pdf}
  \caption{}
  \label{fig:Figure0}
  \end{figure} 
  \clearpage
  \newpage
  \begin{figure}[!t]
  \centering
  \includegraphics{Graph/fig4.pdf}
  \caption{}
  \label{fig:MRA-Figure1}
  \end{figure}
  \clearpage
  \newpage 
  \begin{figure}[!t]
  \centering
  \includegraphics[scale=1]{Graph/fig5.pdf}
  \caption{}
  \label{fig:EMBlockDiagram}
  \end{figure}
  \clearpage
  \newpage 
  \begin{figure}[!t]
   	\centering
   		\includegraphics[scale=1]{Graph/fig6.pdf}
   		\caption{}  
  \label{fig:ObservationFrequencyResponce} 
   \end{figure}
  \clearpage
  \newpage
  \begin{figure}[t]
   	\centering
   		\includegraphics[scale=1]{Graph/fig7.pdf}
   		\caption{} 
  \label{fig:MRA-Convergence}  
   \end{figure}  
   \clearpage
  \newpage
  \begin{figure}[!t]  
   \centering
  \includegraphics{Graph/fig8.pdf}
  \caption{}
  \label{fig:KernelEstimate}
  \end{figure}
  \clearpage
  \newpage
  \begin{figure}[!t]
  \centering
  \includegraphics{Graph/fig9.pdf}
  \caption{}
  \label{fig:FieldEstimates100}
  \end{figure}
  \clearpage
  \newpage
   \begin{figure}[!t]	 
   	\centering
   		\includegraphics[scale=1]{Graph/fig10.pdf}
   		\caption{}
  \label{fig:RMSE}
   \end{figure}
   \clearpage
  \newpage
  \begin{figure}[t]
  	\centering
  		\includegraphics[scale=1]{Graph/fig11.png}
  	\caption{} 
  \label{fig:FieldEstimation}
  \end{figure}        
\clearpage
\newpage   
\appendix
\section{Inner product of two B-spline scaling functions}\label{ap:InnerProductOfBsplines}
In this section, an analytic formula is derived for the inner product of two B-spline scaling functions. Consider two B-spline scaling functions of order $m$ and $m'$. The support of $N_m\left(r\right)$ is $\left[ 0,m\right]$ and  is symmetric with respect to $r=\frac{m}{2}$, i.e.
\begin{align}\label{eq:APP-SymmetrySplieEq}
 N_{m}\left(\frac{m}{2}+r\right)=N_{m}\left(\frac{m}{2}-r\right).
\end{align}
A direct consequence of Eq.~\eqref{eq:APP-SymmetrySplieEq} is 
\begin{align}
 N_{m}\left(r\right)=N_{m}\left(m-r\right).
\end{align}
Therefore
\begin{align}
\int_{-\infty}^{+\infty}N_{m}\left(r-l_{1}\right)N_{m'}\left(r-l_{2}\right)dr&=\int_{-\infty}^{+\infty}N_{m}\left(m-r+l_{1}\right)N_{m'}\left(r-l_{2}\right)dr \nonumber \\
&=\int_{-\infty}^{+\infty}N_{m}\left(m+l_{1}-l_{2}-u\right)N_{m'}\left(u\right)du \nonumber \\
&=\left(N_m \ast N_{m'}\right) \left(m+l_{1}-l_{2}\right) \nonumber \\
&=N_{m+m'}\left(m+l_{1}-l_{2}\right) \nonumber \\
&=N_{m+m'}\left(m'+l_{2}-l_{1}\right).
\end{align} 
\section{Fourier transform of B-spline wavelets}\label{ap:FourierofBsplines}
\parham{To calculate the frequency response of the B-spline wavelet the Fourier transform of $N_1(r)$ is first calculated, 
\begin{align}\label{eq:MRA-N1Fouriertransform}
\mathcal F(N_1(r))&=\int_{-\infty}^{+\infty}N_1(r)\mathrm{exp}(-2\pi i \nu r)dr \nonumber \\
&=\int_{0}^{1} \mathrm{exp}(-2\pi i \nu r)dr \nonumber \\
&=\frac{1-\mathrm{exp}(-2\pi i \nu)}{2\pi i\nu},
\end{align}
The convolution theorem states that the Fourier transform of the convolution of functions is equal to the product of their Fourier transforms. Therefore, taking Fourier transform of Eq.~\eqref{eq:N1convolutions} and substituting Eq.~\eqref{eq:MRA-N1Fouriertransform} for $\mathcal F(N_1(r)) $ yields
\begin{align}\label{eq:MRA-NmFouriertransform}
\mathcal F(N_m(r))=\left(\frac{1-\mathrm{exp}(-2\pi i \nu)}{2\pi i\nu}\right)^{m}.
\end{align}
The Fourier transform of the $m^{th}$ order B-spline allows the calculation of the spatial frequency response of the wavelets using Eq.~\eqref{eq:MRA-TwoScalepair2} giving
\begin{align}      
	  \mathcal{F}(\varphi_{m}\left(r\right)) &= \sum_{n=0}^{3m-2}  q_n \mathcal{F}\left(N_{m}\left(2r-n\right)\right) \nonumber\\
	&=\frac{1}{2}\left(\frac{1-\mathrm{exp}(-\pi i \nu)}{\pi i\nu}\right)^m~\sum_{n=0}^{3m-2}  q_n \mathrm{exp}(-\pi in\nu).\label{app:MRA-Wavelettransform}
\end{align} }
\section{Construction and maximization of the lower bound for the state-space representation of the MRAIDE}\label{ap:QDerivation}
For the linear state-space model given by Eqs.~\eqref{eq:StateEquation} and \eqref{eq:ReducedObservationEquation}. The joint probability distribution $p(\mathbf X,\mathbf Y;\boldsymbol \theta)$ can be written as
 \begin{equation}\label{eq:jointdistribution}
  p(\mathbf X,\mathbf Y;\boldsymbol \theta)=\prod_{t=0}^{T-1} p(\mathbf y_{t+1}|\mathbf x_{t+1})p(\mathbf x_{t+1}|\mathbf x_{t};\boldsymbol \theta)p(\mathbf x_0).
 \end{equation}
The $\mathcal Q$-function, or lower-bound on the likelihood, can be expressed in terms of the joint distribution components
 \begin{align}
  \mathcal Q(\boldsymbol \theta,\boldsymbol\theta')&=\mathbf E_{\boldsymbol \theta'}\left[2\ln p(\mathbf X,\mathbf Y;\boldsymbol \theta)\right] \nonumber \\
 &=\mathbf E_{\boldsymbol\theta'}\left[\sum_{t=0}^{T-1}2\ln p(\mathbf y_{t+1}|\mathbf x_{t+1})+\sum_{t=0}^{T-1}2\ln p(\mathbf x_{t+1}|\mathbf x_{t};\boldsymbol \theta)
 +\sum_{t=0}^{T-1}2\ln p(\mathbf x_0)\right].
 \end{align}   
It should be noted that neither $p(\mathbf y_{t+1}|\mathbf x_{t+1})$ nor $p(\mathbf x_0)$ are functions of the parameter set and therefore the $\mathcal Q$-function can be rewritten as
\begin{equation}
\mathcal Q(\boldsymbol \theta,\boldsymbol\theta')=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}2\ln p(\mathbf x_{t+1}|\mathbf x_{t};\boldsymbol \theta)\right]+\mathrm{constant},
\end{equation}
where the constant term can be ignored as it is independent of the parameters. Under the condition that the state distribution is Gaussian --- ignoring the normalizing term, $1/(2\pi)^{\frac{n_x}{2}}\mid\boldsymbol\Sigma_w\mid^{-\frac{1}{2}}$ --- the conditional distribution $p(\mathbf x_{t+1} | \mathbf x_{t};\boldsymbol\theta)$ can be written as
\begin{align}
p(\mathbf x_{t+1} | \mathbf x_{t};\boldsymbol\theta)=  \exp\left({-\frac{1}{2}\left(\mathbf x_{t+1}-\mathbf A\left(\boldsymbol\theta\right)\mathbf  x_t\right)^\top\boldsymbol\Sigma_w^{-1}\left(\mathbf x_{t+1}-\mathbf A\left(\boldsymbol\theta\right)\mathbf  x_t\right)}\right).
\end{align}
The logarithm of the above distribution, once expanded, is given by
\begin{align}\label{eq:Qfunction}
2\ln p(\mathbf x_{t+1} , \mathbf y_{t+1};\boldsymbol\theta)=&-\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\mathbf x_{t+1}+2\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\mathbf A( \boldsymbol\theta)\mathbf x_t\nonumber \\
&-\mathbf x_t^\top\mathbf A^\top(\boldsymbol\theta)\boldsymbol\Sigma_w^{-1}\mathbf A(\boldsymbol\theta)\mathbf x_t.
\end{align}
The factor of 2 in front of the logarithm is included to simplify the derivation in the later steps. Substituting $\mathbf A( \boldsymbol\theta)$ from Eq.~\eqref{eq:A_theta} into Eq.~\eqref{eq:Qfunction} gives
\begin{align}
2\ln p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\theta)=&\beta+2 T_s\varsigma\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\mathbf x_t \nonumber \\
&-T_s^2\varsigma^2\mathbf x_t^\top \boldsymbol\Lambda_{\theta}^\top\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\mathbf x_t-2\xi \varsigma T_s\mathbf x_t^\top\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\mathbf x_t,\nonumber \\
\end{align}
where 
\begin{equation}
\beta=-\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\mathbf x_{t+1}+2\xi\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\mathbf x_t-\xi^2\mathbf x_t^\top\boldsymbol\Sigma_w^{-1}\mathbf x_t,
\end{equation}
is constant with respect to the parameter $\boldsymbol\theta$, and will disappear subject to differentiation with respect to $\boldsymbol\theta$. Taking the trace and rearranging, using the invariant cyclic permutations property of the trace, this distribution can be written as
\begin{align}\label{eq:Qfunctionintrace}
2\ln p(\mathbf x_{t+1}, \mathbf y_{t+1};\boldsymbol\theta)&=\beta+2 T_s\varsigma\mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_{t+1}^\top\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace \nonumber \\
&-T_s^2\varsigma^2\mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_t^\top \boldsymbol\Lambda_{\theta}^\top\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace\nonumber \\
&-2\xi\varsigma T_s\mathrm{tr} \left\lbrace \mathbf x_t\mathbf x_{t}^\top\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace.
\end{align}
Rearranging and taking the expectation of the log-likelihood function over all time instants gives the required lower-bound, which is to be maximized for the optimal parameter estimates. Note that the expectation distributes over the trace sum. Therefore, 
\begin{align}\label{eq:MRA-QintermsofTraces}
\mathcal Q(\boldsymbol \theta, \boldsymbol\theta')&=\beta+2 T_s\varsigma\mathrm{tr} \left\lbrace \boldsymbol \Xi_0\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace-2\xi\varsigma T_s\mathrm{tr} \left\lbrace \boldsymbol\Xi_1\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace \nonumber \\
&-T_s^2\varsigma^2\mathrm{tr} \left\lbrace \boldsymbol\Xi_1 \boldsymbol\Lambda_{\theta}^\top\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace,
\end{align}
where
\begin{align}
\boldsymbol\Xi_0&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right] \label{eq:app-Xi0}\\
\boldsymbol\Xi_1&=\mathbf E_{\Theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t}^\top\right] \label{eq:app-Xi1}.
\end{align}
The matrices $\boldsymbol\Xi_0$ and $\boldsymbol\Xi_1$ are calculated using the RTS smoother outputs (see \ref{ap:Xiderivation} for more details).

The goal of the remainder of the derivation is to isolate $\boldsymbol\theta$ from the terms forming $\mathcal{Q}$. The three traces that form Eq.~\eqref{eq:MRA-QintermsofTraces} are dealt with in turn. To begin, the first trace is written in terms of element-wise summations
\begin{align}\label{eq:MRA-trace1}
\mathrm{tr} \left\lbrace \boldsymbol \Xi_0\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace&=\sum_{i=1}^{n_x}\left[ \boldsymbol \Xi_0\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right]_{ii} \nonumber \\
&=\sum_{i,j=1}^{n_x}\left[ \boldsymbol\Xi_0\right]_{ij}\left[\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}  \boldsymbol\Lambda_{\theta}\right]_{ji}\nonumber\\
&=\sum_{i,j=1}^{n_x}\left[ \boldsymbol\Xi_0\right]_{ij}\sum_{k=1}^{n_x}\left[\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{jk} \left[ \boldsymbol\Lambda_{\theta}\right]_{ki},
\end{align}
Each element of $\boldsymbol\Lambda_{\theta}$ can be calculated using
\begin{equation}\label{eq:LambdaThetaElements}
\left[ \boldsymbol\Lambda_{\theta}\right] _{k,i}=\left[ \mathbf U\right]^{k,i}\boldsymbol\theta,
\end{equation}
where $\left[ \mathbf U\right] ^{k,i}$ can be computed using Eq.~\eqref{eq:Uij}. By substituting for $\left[ \boldsymbol\Lambda_{\theta}\right] _{k,i}$ from Eq.~\eqref{eq:LambdaThetaElements} the trace given in Eq.~\eqref{eq:MRA-trace1} can be written as
\begin{align}
\mathrm{tr} \left\lbrace \boldsymbol \Xi_0\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace&=\sum_{i,j=1}^{n_x}\left[ \boldsymbol\Xi_0\right]_{ij}\sum_{k=1}^{n_x}\left[ \boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\right]_{jk} \left[ \mathbf U\right]^{k,i}\boldsymbol\theta \nonumber \\
&=\sum_{i,j=1}^{n_x}\left[ \boldsymbol\Xi_0\right]_{ij}\left[ \Gamma_1\right] ^{j,i}\boldsymbol\theta,
\end{align}
where
\begin{align}
\left[ \Gamma_1\right]^{j,i} =\sum_{k=1}^{n_x}\left[ \boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\right]_{jk} \left[ \mathbf U\right]^{k,i}.
\end{align}
The second trace of Eq.~\eqref{eq:MRA-QintermsofTraces} is dealt with in a similar manner, giving
\begin{align}
\mathrm{tr} \left\lbrace \boldsymbol \Xi_1\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace&=
\sum_{i,j=1}^{n_x}\left[ \boldsymbol\Xi_1\right]_{ij}\left[ \Gamma_1\right] ^{j,i}\boldsymbol\theta.
\end{align}
Likewise, the third trace of Eq.~\eqref{eq:MRA-QintermsofTraces} is broken down into element-wise summations
\begin{align}
\mathrm{tr} \left\lbrace \boldsymbol\Xi_1 \boldsymbol\Lambda_{\theta}^\top\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1}\boldsymbol\Lambda_{\theta}\right\rbrace&=\sum_{i,j,k,m=1}^{n_x}\left[\boldsymbol\Xi_1\right] _{i,j}[\boldsymbol\Lambda_{\theta}^{\top}]_{jk} \left[\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{km}[\boldsymbol\Lambda_{\theta}]_{mi} \nonumber \\
=&\boldsymbol\theta^\top\sum_{i,j=1}^{n_x}\left[\boldsymbol\Xi_1\right] _{i,j}\sum_{k,m=1}^{n_x}[\mathbf U^{\top}]^{jk} \left[\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{km}[\mathbf U]^{mi}~\boldsymbol\theta \nonumber \\
&=\boldsymbol\theta^\top\sum_{i,j=1}^{n_x}\left[\boldsymbol\Xi_1\right] _{i,j}\left[ \Gamma_2\right] ^{j,i}\boldsymbol\theta,
\end{align}
where
\begin{align}
\left[ \Gamma_2\right] ^{j,i}=\sum_{k,m=1}^{n_x}[\mathbf U^{\top}]^{jk} \left[\boldsymbol\Lambda_x^{-1}\boldsymbol\Sigma_w^{-1}\boldsymbol\Lambda_x^{-1} \right]_{km}[\mathbf U]^{mi}.
\end{align}
Therefore the $\mathcal Q$-function can be rewritten as
\begin{equation}\label{eq:appQCompact}
\mathcal Q\left(\boldsymbol \theta,\boldsymbol\theta'\right)=\beta+2T_s\varsigma\left(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1\right)\boldsymbol\theta-T_s\varsigma\boldsymbol\theta^\top\boldsymbol\Upsilon\boldsymbol\theta,
\end{equation}
where 
$\boldsymbol\upsilon_0$, $\boldsymbol\upsilon_1$ and $\boldsymbol\Upsilon$ are defined in Eqs.~\eqref{eq:epsilon0}-\eqref{eq:Epsilon}. By differentiating the $\mathcal Q$-function with respect to $\boldsymbol\theta$ we have
\begin{align}\label{eq:MRA-QDerivative}
\frac{\partial \mathcal Q}{\partial \boldsymbol\theta}&=2T_s\varsigma(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1)^\top-T_s\varsigma(\boldsymbol\Upsilon^\top+\boldsymbol\Upsilon)\boldsymbol\theta \nonumber \\
&=2T_s\varsigma(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1)^\top-2T_s\varsigma\boldsymbol\Upsilon^\top\boldsymbol\theta.
\end{align}
Equating Eq.~\eqref{eq:MRA-QDerivative} to $\mathbf 0$ vector yields
\begin{align}\label{eq:app-thetahat}
\boldsymbol \theta= \boldsymbol\Upsilon^{-\top}(\boldsymbol\upsilon_0-\boldsymbol\upsilon_1)^\top.
\end{align}
The second derivative of the $\mathcal Q$-function is given by
\begin{equation}
\frac{\partial^2\mathcal Q}{\partial\boldsymbol\theta^2}=-2T_s\varsigma\boldsymbol\Upsilon.
\end{equation}
The matrix $\boldsymbol\Upsilon$ is positive definite if $n_x^2\times n_{\theta}$ matrix $\mathrm{vec}(\mathbf U)$ is of rank $n_{\theta}$ (\citep{Dewar2009}, Lemma 3), where $\mathrm{vec}(\cdot)$ denotes the vectorization operator. Under this condition $\boldsymbol\Upsilon$ is  invertible and the second derivative is negative definite representing a maximum of the $\mathcal Q$-function.  
\section{Calculation of $\boldsymbol\Xi_{0}$ and $\boldsymbol\Xi_{1}$}\label{ap:Xiderivation}
The expressions for $\boldsymbol\Xi_{0}$ and $\boldsymbol\Xi_{1}$ in terms of smoother outputs can be found in \cite{Shumway2000}, here the derivation is presented for completeness.  We start with the expression for  $\boldsymbol\Xi_{0}$ as defined in Eq.~\eqref{eq:app-Xi0} 
   \begin{equation}\label{eq:appXi0}
	 \boldsymbol\Xi_0=\mathbf E_{\theta'}\left[\sum_{t=0}^{T-1}\mathbf x_t\mathbf x_{t+1}^\top\right].
	\end{equation}                                                                                                
	First we compute the cross-covariance matrix giving
	
\begin{align}\label{eq:Xi0derivation0} 
 \mathbf M_{t+1}&=\mathbf E_{\theta'}\left[(\mathbf x_t-\mathbf{\hat x}_t^b)(\mathbf x_{t+1}-\mathbf{\hat x}_{t+1}^b)^\top\right] \nonumber \\
&=\mathbf E_{\theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\mathbf E_{\theta'}\left[\mathbf x_t\hat{\mathbf x}_{t+1}^{b\top}\right]-\mathbf E_{\theta'}\left[\hat{\mathbf x}_t^b\mathbf x_{t+1}^\top\right]+\mathbf E_{\theta'}\left[\hat{\mathbf x}_t^b\hat{\mathbf x}_{t+1}^{b\top}\right]  \nonumber \\
&= \mathbf E_{\theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\hat{\mathbf x}_t^b\hat{\mathbf x}_{t+1}^{b\top}-\hat{\mathbf x}_t^b\hat{\mathbf x}_{t+1}^{b\top}+\hat{\mathbf x}_t^b\hat{\mathbf x}_{t+1}^{b\top}\nonumber \\
&= \mathbf E_{\theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]-\hat{\mathbf x}_t^b\hat{\mathbf x}_{t+1}^{b\top}.
\end{align}
Rearranging Eq.~\eqref{eq:Xi0derivation0} gives
\begin{equation}\label{eq:Xi0derivation1}
 \mathbf E_{\theta'}\left[\mathbf x_t\mathbf x_{t+1}^\top\right]=\mathbf M_{t+1}+\mathbf {\hat x}_t^b\mathbf{\hat x}_{t+1}^{b\top}.
\end{equation}
Substituting Eq.~\eqref{eq:Xi0derivation1} into Eq.~\eqref{eq:appXi0}, noting the expectation commutes with the sum yields
\begin{equation}
 \boldsymbol\Xi_0=\sum_{t=0}^{T-1}\left(\mathbf M_{t+1}+\mathbf{\hat x}_t^b\mathbf{\hat x}_{t+1}^{b\top}\right).
\end{equation}   
An expression for $\boldsymbol\Xi_1$ in terms of the smoothed states can be also found in a similar way by calculating the covariance matrix, $\mathbf P_t^b$ and following the above steps. 
\newpage
 \bibliographystyle{./elsarticle/model2-names}  
% \bibliographystyle{model2-names} 
\bibliography{MRAIDE}
\end{document}


